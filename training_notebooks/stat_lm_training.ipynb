{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef9eaff1-3d7c-4179-a150-2f719603aebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a90a5d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64795249-6764-426f-bdcf-9c6811cda4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alm/miniforge3/envs/assistant_nlp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "444e6703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stat_lm import Tokenizer, StatLM, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1975d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('Den4ikAI/russian_dialogues', split=\"train[:30%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64390234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/706036 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 706036/706036 [00:24<00:00, 29417.09it/s]\n",
      "100%|██████████| 37160/37160 [00:01<00:00, 27510.29it/s]\n"
     ]
    }
   ],
   "source": [
    "train_texts = []\n",
    "test_texts = []\n",
    "\n",
    "data_len = len(data)\n",
    "\n",
    "train_part = int(0.95*data_len)\n",
    "\n",
    "for i in tqdm(range(train_part)):\n",
    "    d = data[i]\n",
    "    if d['relevance'] == 1:\n",
    "        text = f\"{d['question']} {d['answer']}\"\n",
    "        train_texts.append(text)\n",
    "\n",
    "test_texts = []\n",
    "for i in tqdm(range(train_part, data_len)):\n",
    "    d = data[i]\n",
    "    if d['relevance'] == 1:\n",
    "        text = f\"{d['question']} {d['answer']}\"\n",
    "        test_texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa51a7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "можно ли смотреть телевизор через компьютер? да tv тюнер надо покупать\n",
      "я считаю, что лучше быть грешным, чем слыть грешным. кто согласен и почему? грехи разные, как и слава. поступайте разумно.\n",
      "когда делаешь упражнения на трицепс, руку не полностью выпрямлять под конец? да, чтобы нагрузка с трицепса не уходила.\n",
      "это правда что рубин обыграл барселону, как это произошло? старание и труд помноженное на везение творят чудеса. советую посмотреть матч\n",
      ". можно так сильно у пасть что бы по купить любовь? про дать? а толку. любой товар имеет срок годности.\n",
      "если любимый человек, после обиды становится противен, значит любви никакой и не было? а любовь это не всегда сладкая вата. иногда и горький мед.\n",
      "а я люблю рубу и собак и есть за что. верные. хвостом виляют\n",
      "докажи кинь член тебе своего мало?\n",
      "а не кому, сейчас вообще не знаешь кому верить, истории даже переписывают вся наша история наверное ложь\n",
      "ваша вера вас спасла? вера во что? вера в свои силы. в свой дух, в свою разумность.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    index = int(len(train_texts)*random.random())\n",
    "    print(train_texts[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b2470f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = train_texts + test_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "547bb00f-8e7e-4cdf-9471-77537469f4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer().build_vocab(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c245b6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stat_lm.Tokenizer at 0x7f1f6c8e9b50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "319547b3-3f12-4cb8-8380-f75cc0a1d907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303535"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cac9845-d306-4528-9796-396c5fb602a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_example = \"В России люди любят искать приключения на голову\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90552be8-0c55-4283-ab5e-cfcdff377145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[230340, 1714, 23623, 90703, 56427, 52295, 130223, 86695, 303532]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50920ab8-e8f6-4392-9b85-b6fe2ccbbee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['в', 'россии', 'люди', 'любят', 'искать', 'приключения', 'на', 'голову']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer._tokenize(text_example, append_eos_token=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec382de3-5267-434d-aa5c-8c6aafec92aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'в россии люди любят искать приключения на голову'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text_example), remove_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8233fc65-237c-477c-94f4-a655c4a0a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_lm = StatLM(tokenizer, context_size=3, alpha=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08233541-1854-45c4-85a7-4dbab69e33a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"обучаем\" модель - считаем статистики\n",
    "stat_lm.train(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cc3b629-22dc-49a0-8607-fa02ee0b0d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'temperature': 1.2,\n",
    "    'max_tokens': 30,\n",
    "    'sample_top_p': 5,\n",
    "    'decoding_strategy': 'top-p',\n",
    "    'gen_decay': 1,\n",
    "}\n",
    "\n",
    "generation_config = GenerationConfig(temperature=config['temperature'],\n",
    "                                     max_tokens=config['max_tokens'],\n",
    "                                     sample_top_p=config['sample_top_p'],\n",
    "                                     decoding_strategy=config['decoding_strategy'],\n",
    "                                     gen_decay=config['gen_decay'],\n",
    "                                     remove_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac983cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "а я просто степан, музыку пишу дратуйти qcy qcy торопитесь\n",
      "end of text \n",
      "\n",
      "а правда ли что сколько людей столько и мнений? почему? да, но не всегда. но не все, что это может быть? если нет,\n",
      "max tokens \n",
      "\n",
      "осознание того, что ты желанен придает тебе уверенности? знания, и не надо. а если в семье. а вот интересно, а не с чем связано\n",
      "max tokens \n",
      "\n",
      "кстати, если вы знаете хороших людей, то просьба использовать сарафанное радио и рассказать о чате у славы о, да и то же? если нет, не\n",
      "max tokens \n",
      "\n",
      "а вот как актер вицин чем больше тем лучше. а что для вас значит? что бы вы хотели бы вы хотели бы вы хотели бы вы хотели бы\n",
      "max tokens \n",
      "\n",
      "мелировка волос это красиво, или уже не модно? это когда не надо, чтобы не было. а вот в этом году? если да, то как\n",
      "max tokens \n",
      "\n",
      "серьезно ждешь? я то серьезно могу кинуть если надо. а у вас? и почему? я не знаю, но не знаю, я не хочу быть\n",
      "max tokens \n",
      "\n",
      "верите ли вы сонникам? верите что можно приготовить из куриного филе, можно ли считать это безусловным добром\n",
      "end of text \n",
      "\n",
      "а какой виртуальный подарок. вы ждете на новый год? а что вы будете делать? а я не хочу. как думаете, почему? я думаю,\n",
      "max tokens \n",
      "\n",
      "а ты сделал дело? гуляешь смело? нанять личного преподавателя, недорого и с чем это может быть? а что для вас значит счастье? счастье это когда\n",
      "max tokens \n",
      "\n",
      "меня посылали, что дальше? дальше больше о себе. и не будет. а вот с утра. это же не всегда. а вот если я не\n",
      "max tokens \n",
      "\n",
      "а у вас кнопочный телефон? на что- то. не люблю. я не хочу. но не всегда. и это тоже работа. но не в\n",
      "max tokens \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    index = train_part + int(len(test_texts)*random.random())\n",
    "    d = data[index]\n",
    "    if d['relevance'] == 1:\n",
    "        text = d['question']\n",
    "        generated = stat_lm.generate_text(text, generation_config)\n",
    "        print(generated['total_text'])\n",
    "        print(generated['finish_reason'], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01741b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "как дела? хорошо отношусь. это не значит, что бы не стал. эт про чтото интересное было, а вот если бы я был не прав.\n",
      "max tokens \n",
      "\n"
     ]
    }
   ],
   "source": [
    "generated = stat_lm.generate_text(\"Как дела?\", generation_config)\n",
    "print(generated['total_text'])\n",
    "print(generated['finish_reason'], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0b630e5-a8eb-4142-a809-e06cdad02b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save('tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d15ea36f-6ab9-4e1c-9973-1d90ce4e4cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_lm.save_stat('stat_lm.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
