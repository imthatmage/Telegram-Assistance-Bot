{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4bff092-423a-4a28-b780-a51a614e8004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import bitsandbytes as bnb\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "# using the style for the plot \n",
    "plt.style.use('dark_background') \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "811d70fe-0839-4b88-a1a9-715e4894d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed the same seed to all \n",
    "def seed_everything(seed=42):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f92e6b-68e8-4d0e-a5b9-f4d08e56df7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f7154be37b54e71a75319d687db7923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    load_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model =AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea34108f-b4e3-4857-a81b-421ba45420dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36f814d6-2283-4a3b-a128-44d86c26e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "  \"\"\"\n",
    "  Prints the number of trainable parameters in the model.\n",
    "  \"\"\"\n",
    "  trainable_params = 0\n",
    "  all_param = 0\n",
    "  for _, param in model.named_parameters():\n",
    "    all_param += param.numel()\n",
    "    if param.requires_grad:\n",
    "      trainable_params += param.numel()\n",
    "  print(\n",
    "      f\"trainable params: {trainable_params} || all params: {all_param} || trainables%: {100 * trainable_params / all_param}\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09a94e9d-bb14-42ab-8d6e-1686d37aece3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaef6a4-c5d6-4cc0-a132-84cfcaa31229",
   "metadata": {},
   "source": [
    "## Lora Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "801669d6-1a84-4896-aa08-75d61285d769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 37748736 || all params: 3789819904 || trainables%: 0.9960561967643304\n"
     ]
    }
   ],
   "source": [
    "config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf529c1a-40d3-4d06-b320-9b38984ea8d9",
   "metadata": {},
   "source": [
    "# Load Dataset (ru_instruct_gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31d6a6a5-3ada-4a28-ade8-27d46a175bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "  return f\"\"\"\n",
    "### Task: {data_point[\"instruction\"]}\n",
    "### Input: {data_point[\"input\"]}\n",
    "Output: {data_point[\"output\"]}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe596023-c57d-4fc1-8264-8c4ab9464ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for lksy/ru_instruct_gpt4 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/lksy/ru_instruct_gpt4\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"lksy/ru_instruct_gpt4\", split=\"train\")\n",
    "data = data.train_test_split(test_size=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d6d0005-6fee-4a97-bcc7-f96d295d62c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'full_output'],\n",
       "        num_rows: 14453\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'full_output'],\n",
       "        num_rows: 603\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd989a5-aa30-4349-9238-705eb458b9f2",
   "metadata": {},
   "source": [
    "## Check Model Performance Without Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "677877d5-80e3-43c8-b0e6-36758e2f8b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры для генерации\n",
    "generation_params = {\n",
    "    \"max_new_tokens\": 150,\n",
    "    \"num_beams\": 1,\n",
    "    \"early_stopping\": True,\n",
    "    \"no_repeat_ngram_size\": 2,\n",
    "    \"eos_token_id\": tokenizer.eos_token_id,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7866087a-87ae-4c73-963e-181f00826454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:453: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(len(data['test']))\n",
    "task = (data['test'][i]['instruction'] + '\\n' + data['test'][i]['input']).strip()\n",
    "prompt = f'### Задание: {task}\\n\\n### Ответ:'\n",
    "\n",
    "device = \"cuda:0\"\n",
    "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids = encoding.input_ids,\n",
    "        attention_mask = encoding.attention_mask,\n",
    "        **generation_params,\n",
    "    )\n",
    "pred_text = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50065016-e188-41fd-983a-760a7819f0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('### Задание: Вам представлено литературное произведение и его автор. Расскажите кратко о сюжете произведения.\\n\"Война и мир\" Льва Толстого.\\n\\n### Ответ:\\nВ романе \"Великая Отечественная война 1812 года\" (1969) Л.Н. Тольстой описывает события, происходившие в России в 25-м году жизни автора. В роман входят 5 книг, 49 глав, в которых описаны социальные, политические и военные совершенно разные реалии. Роман написан в форме исторического родословца, повествующего о судьбах нескольких родов, охватывающих все слои общества',\n",
       " 270)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_text, i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2d879c-690f-416e-8132-04ae665089d2",
   "metadata": {},
   "source": [
    "## Few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41d239c1-1f08-4ed2-bb4f-ed3f1e9a0c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Task: Расскажи о своей любимой книге, почему ты ее любишь, что особенного в ней для тебя.\n",
      "### Input: Любимая книга: Маленький принц\n",
      "Output: Моя любимая книга - \"Маленький принц\" Антуана де Сент-Экзюпери. Это история о маленьком принце с другой планеты, который отправился на поиски друзей и мудрости. Я люблю эту книгу, потому что она наполнена волшебством и глубокими философскими мыслями, которые касаются жизни, дружбы, любви и человеческих отношений. Особенное для меня в этой книге то, что, несмотря на то, что она изначально написана для детей, она подходит для людей всех возрастов, поскольку содержит уроки и прозрения, актуальные для каждого из нас в любом возрасте. Книга учит нас ценить маленькие радости жизни, взаимоотношения, и что искренность и бескорыстность - самые важные ценности.\n",
      "-----------------------------\n",
      "### Task: Преобразуй следующую дату в человеко-читаемый формат: день недели, число, месяц, год.\n",
      "### Input: 2023-08-12\n",
      "Output: Суббота, 12 августа 2023 года\n",
      "-----------------------------\n",
      "### Task: Сравните между собой два предмета по заданным параметрам.\n",
      "### Input: Предметы: лампа накаливания и светодиодная лампа. Параметры: эффективность, долговечность и воздействие на окружающую среду.\n",
      "Output: В сравнении с лампой накаливания, светодиодная лампа обладает более высокой эффективностью, долговечностью и меньшим воздействием на окружающую среду.\n",
      "-----------------------------\n",
      "### Task: Опиши причины и последствия Загадочного случая с локомоночником.\n",
      "### Input: Он пришел в бар один, покупал выпивку только себе, и все время что-то нашептывал.\n",
      "Output: Загадочный случай с локомоночником начался с того, что мужчина пришел в бар один, заказывал напитки только для себя и постоянно что-то нашептывал. Возможно, он был под страхом или переживал стресс, в результате чего странно вел себя и привлек к себе внимание окружающих. Последствия этого могут быть разными, вплоть до вмешательства полиции или заботливого поступка прохожих, пытающихся выяснить, что случилось и предложить помощь.\n",
      "-----------------------------\n",
      "### Task: Расскажите о концертных залах и видах мероприятий, которые можно провести в них.\n",
      "### Input: Название: Дом Музыки; Местоположение: Санкт-Петербург.\n",
      "Output: Дом Музыки в Санкт-Петербурге – это современный концертный комплекс, предлагающий разнообразные залы для проведения самых разных мероприятий. Здесь можно организовать концерты классической, джазовой, рок- или поп-музыки, а также провести театральные постановки, танцевальные шоу и многое другое. Благодаря уникальной архитектуре и отличной акустике, любое мероприятие в Доме Музыки станет незабываемым для зрителей и участников.\n",
      "-----------------------------\n",
      "### Task: Ответьте на вопрос о причинах колебаний количества жителей Земли в течение истории человечества.\n",
      "### Input: \n",
      "Output: Колебания количества жителей Земли в течение истории связаны с множеством факторов, таких как изменения в климате, миграции, болезни, войны, изменения в питании и технологиях, а также уровень образования и доступность медицинских услуг.\n",
      "-----------------------------\n",
      "### Task: Дай определение и примеры из жизни для психологического термина \"конформизм\".\n",
      "### Input: \n",
      "Output: Конформизм - это психологическое явление, когда индивид приспосабливается к поведению и мнениям группы, даже если это противоречит его личным убеждениям. Примеры из жизни: 1) подросток, который начинает курить, чтобы быть принятым в компанию сверстников; 2) сотрудник, который соглашается с непопулярным решением начальника, чтобы не выделяться и избежать конфликтов на работе.\n",
      "-----------------------------\n",
      "### Task: Составь текст объявления для продажи автомобиля.\n",
      "### Input: Модель: Toyota Corolla. Год выпуска: 2014. Пробег: 75 000 км. Цена: 600 000 рублей. Комплектация: электропривод зеркал, климат-контроль, круиз-контроль, парктроник, подогрев сидений.\n",
      "Output: Продаю Toyota Corolla 2014 года выпуска с пробегом 75 000 км, в отличном состоянии. Автомобиль оснащен: электроприводом зеркал, климат-контролем, круиз-контролем, парктроником и подогревом сидений. Цена: 600 000 рублей. Если вам нужен надежный, экономичный автомобиль с прекрасной комплектацией, то это предложение для вас! Звоните и приходите смотреть автомобиль.\n",
      "-----------------------------\n",
      "### Task: Напиши стихотворение на основе предложенного тематического слова.\n",
      "### Input: зима\n",
      "Output: Зима, зима, волшебница,\n",
      "Сквозь снег и мороз блещешь,\n",
      "Приносишь снегопады, праздники,\n",
      "В город и деревню тишина влечешь.\n",
      "-----------------------------\n",
      "### Task: Используя поставленные слова, составьте одно сложное предложение.\n",
      "### Input: компьютер, рабочий стол, документы, печать\n",
      "Output: На рабочем столе стоял компьютер, на котором были открыты важные документы, готовые для печати.\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    tmp = data[\"train\"][i]\n",
    "    print(generate_prompt(tmp))\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0242a2e4-396a-42af-a474-eff56bdd0652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'На рабочем столе стоял компьютер, на котором были открыты важные документы, готовые для печати.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_prompt = generate_prompt(tmp)\n",
    "ex_prompt[ex_prompt.find(\"Output: \") + 8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0ff8906-a394-4bae-9f00-3cc3cd5b5af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'instruction': (self.data[idx]['instruction'] + '\\n' + self.data[idx]['input']).strip(),\n",
    "            'output': self.data[idx]['output'].strip()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af8d99c6-62c1-493f-86fb-3183d643b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    inputs, outputs = [], []\n",
    "    \n",
    "    for x in data:\n",
    "        inp = f'### Задание: {x[\"instruction\"]}\\n\\n### Ответ:'\n",
    "        input_ids = tokenizer(\n",
    "            inp,\n",
    "            add_special_tokens=True\n",
    "        )['input_ids']\n",
    "        label_ids = tokenizer(\n",
    "            x['output'] + tokenizer.eos_token,\n",
    "            add_special_tokens=False,\n",
    "            max_length=512,\n",
    "            truncation=True\n",
    "        )['input_ids']\n",
    "        inputs.append(torch.tensor(input_ids + label_ids))\n",
    "        outputs.append(torch.tensor([-100] * len(input_ids) + label_ids))\n",
    "        \n",
    "    input_ids = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(outputs, batch_first=True, padding_value=-100)\n",
    "        \n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'labels': labels,\n",
    "        'attention_mask': input_ids.ne(0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fff6c7b8-8bb2-43c8-a6f3-8ab7e7ca50d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(data['train'])\n",
    "eval_dataset = Dataset(data['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adef136e-4296-4ac8-bb42-83c1dbe34a32",
   "metadata": {},
   "source": [
    "# Metrics setup and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1f0f497-53ba-4e0d-80a6-0a6226ce0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import nltk\n",
    "\n",
    "metric = evaluate.load('rouge')\n",
    "def rouge_bleu_custom(pred):\n",
    "    references = pred.label_ids\n",
    "    predictions = pred.predictions[0]\n",
    "\n",
    "    ref_sent = []\n",
    "    pred_sent = []\n",
    "    macro_bleu = 0\n",
    "    for ref, predicted in zip(references, predictions):\n",
    "        # replace -100 with pad token\n",
    "        ref[ref == -100] = tokenizer.eos_token_id\n",
    "        ref_decoded = tokenizer.decode(ref, skip_special_tokens=True)\n",
    "        predicted[predicted == -100] = tokenizer.eos_token_id\n",
    "        predicted_decoded = tokenizer.decode(predicted, skip_special_tokens=True)\n",
    "        ref_sent.append(ref_decoded)\n",
    "        pred_sent.append(predicted_decoded)\n",
    "        \n",
    "        bleu_score = nltk.translate.bleu_score.sentence_bleu(\n",
    "                [ref_decoded],\n",
    "                predicted_decoded,\n",
    "                weights = [0.334, 0.333, 0.333]\n",
    "        )\n",
    "        macro_bleu += bleu_score\n",
    "    metrics_dict = metric.compute(predictions=pred_sent, references=ref_sent)\n",
    "    metrics_dict['bleu'] = macro_bleu / len(references)\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b9c3597-e4a7-4920-bc8d-336e97e72a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    \"\"\"\n",
    "    Original Trainer may have a memory leak. \n",
    "    This is a workaround to avoid storing too many tensors that are not needed.\n",
    "    \"\"\"\n",
    "\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    return pred_ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f765e816-db25-4ebf-8d89-9b1d6c58b4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1204' max='1204' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1204/1204 3:59:32, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.912200</td>\n",
       "      <td>0.840293</td>\n",
       "      <td>0.195158</td>\n",
       "      <td>0.124346</td>\n",
       "      <td>0.192962</td>\n",
       "      <td>0.193616</td>\n",
       "      <td>0.532981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.728600</td>\n",
       "      <td>0.838902</td>\n",
       "      <td>0.198231</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.195933</td>\n",
       "      <td>0.196673</td>\n",
       "      <td>0.531685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1204, training_loss=0.8077275748565743, metrics={'train_runtime': 14385.2623, 'train_samples_per_second': 2.009, 'train_steps_per_second': 0.084, 'total_flos': 3.527448961320714e+17, 'train_loss': 0.8077275748565743, 'epoch': 2.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "      per_device_train_batch_size=6,\n",
    "      per_device_eval_batch_size=1,\n",
    "      gradient_accumulation_steps=4,\n",
    "      eval_accumulation_steps=4,\n",
    "      num_train_epochs=2,\n",
    "      learning_rate=2e-4,\n",
    "      fp16=True,\n",
    "      save_total_limit=5,\n",
    "      output_dir=\"experiments\",\n",
    "      optim=\"paged_adamw_8bit\",\n",
    "      lr_scheduler_type=\"cosine\",\n",
    "      warmup_ratio=0.05,\n",
    "      logging_dir = './logs',\n",
    "      report_to = 'tensorboard',\n",
    "      load_best_model_at_end = True,\n",
    "      evaluation_strategy ='epoch',\n",
    "      eval_steps=250,\n",
    "      logging_strategy='steps',\n",
    "      logging_steps=1,\n",
    "      save_strategy='epoch',\n",
    "      save_steps=2000,\n",
    "      seed=SEED,\n",
    "      remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=rouge_bleu_custom,\n",
    "    data_collator=collate_fn,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e2b34-14bc-41e4-b103-2a3b80e863a0",
   "metadata": {},
   "source": [
    "## Check Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45aee4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bitsandbytes as bnb\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "# using the style for the plot \n",
    "plt.style.use('dark_background') \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e0d67b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    load_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b5fe7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 2/2 [09:44<00:00, 292.03s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.95s/it]\n"
     ]
    }
   ],
   "source": [
    "PEFT_MODEL = \"../models/mistral_7b\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(PEFT_MODEL)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    return_dict=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b5e0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model, PEFT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9c1cdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alm/miniforge3/envs/assistant_nlp/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for lksy/ru_instruct_gpt4 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/lksy/ru_instruct_gpt4\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"lksy/ru_instruct_gpt4\", split=\"train\")\n",
    "data = data.train_test_split(test_size=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb89a5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.682e+03, 4.727e+03, 3.773e+03, 1.077e+03, 1.600e+02, 2.600e+01,\n",
       "        6.000e+00, 1.000e+00, 0.000e+00, 1.000e+00]),\n",
       " array([1.0000e+00, 1.9370e+02, 3.8640e+02, 5.7910e+02, 7.7180e+02,\n",
       "        9.6450e+02, 1.1572e+03, 1.3499e+03, 1.5426e+03, 1.7353e+03,\n",
       "        1.9280e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_len = []\n",
    "\n",
    "for i in range(len(data['train'])):\n",
    "    output_len.append(len(data['train'][i][\"output\"]))\n",
    "plt.hist(output_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce3b19a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of Train Output Len: 298.0\n",
      "Mean of Train Output Len: 307.27\n"
     ]
    }
   ],
   "source": [
    "print(f\"Median of Train Output Len: {np.median(output_len)}\")\n",
    "print(f\"Mean of Train Output Len: {np.mean(output_len):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be3dfc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры для генерации\n",
    "generation_params = {\n",
    "    \"max_new_tokens\": 300,\n",
    "    \"num_beams\": 3,\n",
    "    \"early_stopping\": True,\n",
    "    \"no_repeat_ngram_size\": 2,\n",
    "    \"eos_token_id\": tokenizer.eos_token_id,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a0c27f",
   "metadata": {},
   "source": [
    "## Рассмотрим обработку текстов из валидационного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdea5751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Задание: Опиши процесс проведения торгов на бирже и основные инструменты, с которыми работают участники.\n",
      "\n",
      "### Ответ: Торговая площадка - это место, где происходит обмен ценными бумагами и другими финансовыми активами между инвесторами и специализированными организациями. Процесс торгования начинается с регистрации участников и получения доступа к информации о текущих курсах акций, фондовых индексов, валютных пар и т.д. Затем участник определяет стратегию и анализирует рыночные тенденции, чтобы сделать правильные решения о покупке или продаже инвентаря. Основными индикаторами, которые помогают в оценке рисков и возможностей, являются технические и экономические показатели, а также новости и прогнозы экспертов. Инструментами для участия в торгах служат брокерские услуги, онлайн-платформы и мобильное приложения, позволяющие контролировать свой портфель и выполнять операции в режиме реального времени.\n",
      "---------------------------------\n",
      "Оригинальный ответ: На бирже процесс торгов включает покупку и продажу финансовых инструментов, таких как акции, облигации, опционы, фьючерсы и валюты. Участники торгов, такие как инвесторы и трейдеры, могут размещать заявки на покупку или продажу, которые затем сопоставляются с другими участниками рынка. Биржевые операции обычно осуществляются через брокеров, предоставляющих доступ к биржевой платформе. Основные инструменты, с которыми работают участники, включают анализ цен, фундаментальный и технический анализ, различные индексы и показатели, а также разнообразные стратегии торговли.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Создай диалог между двумя персонажами на основе входных данных.\n",
      "Лиана — ветеринарный врач, Карина — владелец собаки\n",
      "\n",
      "### Ответ: Лиана: Здравствуйте! Как дела с Вашей собой?\n",
      "Карына: Привет! Все в порядке, спасибо. А у Вас что нового в клинике?\n",
      "---------------------------------\n",
      "Оригинальный ответ: Лиана: Здравствуйте, Карина! Что случилось с вашей собакой?\n",
      "Карина: Здравствуйте, Лиана. Она в последнее время стала часто кашлять, и ей становится тяжело дышать.\n",
      "Лиана: Хорошо, я осмотрю её и определю возможную причину проблемы.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Опиши рецепт приготовления омлета из трех ингредиентов.\n",
      "яйца, молоко, сыр\n",
      "\n",
      "### Ответ: 1. Взбейте 4 яйцевых белка и 200 мл молока в миске до однородной консистенции. \n",
      "2. Разогрейте сковороду с маслом на среднем огне и вылейте яичную смесь. Закройте крышкой и жарьте до готовности, примерно 5-7 минут.\n",
      "---------------------------------\n",
      "Оригинальный ответ: Для приготовления омлета необходимо взбить 4 яйца с 50 мл молока, добавить немного соли и перемешать. Затем, на разогретой сковороде со сливочным маслом, вылить смесь и готовить на среднем огне. После того, как омлет начнет загустевать, посыпать его тертым сыром и закрыть крышкой на 2-3 минуты, чтобы сыр расплавился. Готовый омлет аккуратно перевернуть на тарелку и подавать горячим.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Опиши фантастическую технологию, которая сделает нашу жизнь лучше и счастливее.\n",
      "\n",
      "### Ответ: Технология, способная превратить воду в энергию без выбросов парниковых газов, станет революционным шагом в борьбе с глобальным потеплением и обеспечит экологически чистый и безопасный источник электричества для всего мира.\n",
      "---------------------------------\n",
      "Оригинальный ответ: Представьте себе устройство, которое мгновенно может телепортировать людей и предметы на любое расстояние, экономя время и ресурсы на передвижение. Это устроит революцию в области транспорта, облегчит коммуникацию и поможет сохранить окружающую среду.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Расскажите о вкладе Николы Теслы в область электроэнергетики и его ключевых изобретениях.\n",
      "\n",
      "### Ответ: Никола Тесла (1856-1943) был выдающимся ученым-электриком сербско-американского происхождения, сделавшим значительный вклад в развитие современных технологий. Его основные достижения включают разработку системы переменного тока с высоким напряжением и низким током, которая стала основой для сегодняшних энергосистем. Также он создал первый прототип радиоуправляемого самолета, а также разрабатывал идеи для беспроводной передачи силы и информации на большие расстояния.\n",
      "---------------------------------\n",
      "Оригинальный ответ: Никола Тесла сыграл важную роль в развитии электроэнергетики, его ключевые изобретения включают такие технологии как переменный ток, трансформаторы высокого напряжения и индукционные двигатели. Благодаря этим открытиям стало возможным эффективная передача электричества на длинные расстояния и были заложены основы современных систем электроснабжения.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Назовите примеры известных спортивных комплексов в Москве, Санкт-Петербурге и Сочи.\n",
      "\n",
      "### Ответ: Москва: Лужники, Олимпийский комплекс \"Спартак\", Центральный стадион \"Динамо\".\n",
      "Сочи: Физкультурно-оздоровительный центр \"Адлер-Арена\", \"Фиш-Стадиум\" и \"Большой сочинский концертный зал\".\n",
      "---------------------------------\n",
      "Оригинальный ответ: В Москве одним из самых известных спортивных комплексов является стадион \"Лужники\". В Санкт-Петербурге - \"Газпром Арена\". В городе Сочи к основным спортивным объектам можно отнести \"Олимпийский парк\", включающий в себя различные стадионы и арены, построенные специально к Олимпийским играм 2014 года.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Расскажи про забавный случай в жизни человека, который был описан в истории на одной странице дневника.\n",
      "27 мая – сегодня наша собака Вилка весь день решила прятаться под диваном, и мы даже придумали новую игру, пытаясь ее вытащить.\n",
      "\n",
      "### Ответ: В детстве у меня была домашняя кошка, которая любила играть в скрытке. Однажды, когда я пришел домой после школы, я обнаружил, что она забаррикадировалась в моем шкафу и не хотела выйти. Мы провели целый вечер в поисках способа вывести кошку на свободу. В конечном итоге, нам пришлось использовать маленькую лестницу, чтобы добраться до нее.\n",
      "---------------------------------\n",
      "Оригинальный ответ: 27 мая произошел забавный случай в жизни человека. Весь день их собака по имени Вилка решила прятаться под диваном, из-за чего вся семья оказалась вовлечена в новую игру. Игра заключалась в том, чтобы пытаться вытащить Вилку из своего укрытия, что превратилось в увлекательное и смешное времяпрепровождение для всех.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Определите последовательность кулинарных шагов для приготовления заданного блюда.\n",
      "омлет с грибами и сыром\n",
      "\n",
      "### Ответ: 1. Разогрейте сковороду с маслом на среднем огне. 2. Нарежьте овощи (помидоры, зелень, лук) и обжаривайте до мягкости, добавив соль и перец по мере необходимости (около 5-7 минут). 3. Отдельно нарежете сыр на небольшие кусочки и поместите их в миску с яйцами (4-5 яиц, по вкусу), дополнительно взбейте смесь до однородной консистенции.\n",
      "---------------------------------\n",
      "Оригинальный ответ: 1) нарезать грибы и лук, 2) обжарить грибы и лук на сковороде, 3) смешать яйца с молоком и специями, 4) налить смесь яиц на сковороду с грибами, 5) посыпать омлет тертым сыром, 6) дать омлету схватиться на среднем огне, затем сложить пополам и подавать.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Опиши процесс работы холодильника.\n",
      "\n",
      "### Ответ: Холдилик работает на основе принципа компрессионного охлаждения. Внутри устройства находится газ, например, хлорфлуороводород (R-134a). Когда сжатая сжимающаяся смесь газа поступает в конденсатор, она остывает и превращается в жидкость. Жидкий хладагент проходит через термостат, который регулирует температуру, и затем попадает во внутреннюю камеру, где нагревается и переходит в газообразное состояние. Газ поглощает тепло от продуктов и воздуха, оставляя их в пространстве. Затем сверхзвуковой клапан отпускает газы обратно в скомпрессор, цикл повторяется.\n",
      "---------------------------------\n",
      "Оригинальный ответ: Холодильник работает по принципу теплообмена между двумя средами – внутренней и внешней. Система основана на использовании хладагента, который испаряется внутри холодильной камеры, отнимая тепло от продуктов и окружающего воздуха. Затем хладагент сжимается компрессором и переходит в конденсатор, где отдает тепло наружной среде и конденсируется. Процесс постоянно повторяется, поддерживая установленную температуру внутри холодильника.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Расскажите о причинах и последствиях Великой Отечественной войны 1941-1945 годов.\n",
      "\n",
      "### Ответ: Вторая мировая война началась с нападения Германии на Советский Союз 22 июня и продолжалась до 9 мая. Причины войны включают в себя стремление Гитлера к мировому господству, агрессивную внешнюю политику Третьего рейха и недоверие между СССР и Западными державами. Последствия войны были огромными: гибель миллионов солдат и гражданских лиц, разрушение городов и инфраструктуры, массовое перемещение населения, экономические и социальные потрясения.\n",
      "---------------------------------\n",
      "Оригинальный ответ: Великая Отечественная война 1941-1945 годов была частью Второй мировой войны и началась с нападения нацистской Германии на СССР 22 июня 1941 года. Основными причинами войны были стремление Германии расширить свои границы, завоевание территорий и экономических ресурсов. Последствия ВОВ включают огромные потери среди населения и разрушение инфраструктуры и экономики страны. Однако, победа над нацизмом позволила СССР стать одной из ведущих мировых держав и сформировать блок социалистических стран, а также расширить влияние на международную политику и экономику.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_data = data['test']\n",
    "\n",
    "for _ in range(10):\n",
    "  i = np.random.randint(len(val_data))\n",
    "  task = (val_data[i]['instruction'] + '\\n' + val_data[i]['input']).strip()\n",
    "  prompt = f'### Задание: {task}\\n\\n### Ответ:'\n",
    "  original_prompt = f'### Задание: {task}\\n\\n### Ответ:'\n",
    "  original_prompt += val_data[i]['output']\n",
    "\n",
    "  device = \"cuda:0\"\n",
    "  encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "  with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids = encoding.input_ids,\n",
    "        attention_mask = encoding.attention_mask,\n",
    "        **generation_params,\n",
    "  )\n",
    "  pred_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "  # sequence_start = pred_text.find(\"Output: \") + 8\n",
    "  print(pred_text)\n",
    "  print(\"---------------------------------\")\n",
    "  print(\"Оригинальный ответ: \" + val_data[\"output\"][i])\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c635a23f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
