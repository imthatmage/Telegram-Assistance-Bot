{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4bff092-423a-4a28-b780-a51a614e8004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import bitsandbytes as bnb\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "# using the style for the plot \n",
    "plt.style.use('dark_background') \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "811d70fe-0839-4b88-a1a9-715e4894d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed the same seed to all \n",
    "def seed_everything(seed=42):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f92e6b-68e8-4d0e-a5b9-f4d08e56df7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb11880e5ac547769face33975f20a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    load_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model =AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea34108f-b4e3-4857-a81b-421ba45420dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36f814d6-2283-4a3b-a128-44d86c26e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "  \"\"\"\n",
    "  Prints the number of trainable parameters in the model.\n",
    "  \"\"\"\n",
    "  trainable_params = 0\n",
    "  all_param = 0\n",
    "  for _, param in model.named_parameters():\n",
    "    all_param += param.numel()\n",
    "    if param.requires_grad:\n",
    "      trainable_params += param.numel()\n",
    "  print(\n",
    "      f\"trainable params: {trainable_params} || all params: {all_param} || trainables%: {100 * trainable_params / all_param}\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09a94e9d-bb14-42ab-8d6e-1686d37aece3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaef6a4-c5d6-4cc0-a132-84cfcaa31229",
   "metadata": {},
   "source": [
    "## Lora Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "801669d6-1a84-4896-aa08-75d61285d769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 150994944 || all params: 3903066112 || trainables%: 3.8686237862014465\n"
     ]
    }
   ],
   "source": [
    "config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=128,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf529c1a-40d3-4d06-b320-9b38984ea8d9",
   "metadata": {},
   "source": [
    "# Load Dataset (ru_instruct_gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31d6a6a5-3ada-4a28-ade8-27d46a175bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "  return f\"\"\"\n",
    "### Task: {data_point[\"instruction\"]}\n",
    "### Input: {data_point[\"input\"]}\n",
    "Output: {data_point[\"output\"]}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe596023-c57d-4fc1-8264-8c4ab9464ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for lksy/ru_instruct_gpt4 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/lksy/ru_instruct_gpt4\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"lksy/ru_instruct_gpt4\", split=\"train\")\n",
    "data = data.train_test_split(test_size=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d6d0005-6fee-4a97-bcc7-f96d295d62c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'full_output'],\n",
       "        num_rows: 14453\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'full_output'],\n",
       "        num_rows: 603\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd989a5-aa30-4349-9238-705eb458b9f2",
   "metadata": {},
   "source": [
    "## Check Model Performance Without Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "677877d5-80e3-43c8-b0e6-36758e2f8b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры для генерации\n",
    "generation_params = {\n",
    "    \"max_new_tokens\": 150,\n",
    "    \"num_beams\": 1,\n",
    "    \"early_stopping\": True,\n",
    "    \"no_repeat_ngram_size\": 2,\n",
    "    \"eos_token_id\": tokenizer.eos_token_id,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7866087a-87ae-4c73-963e-181f00826454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:453: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(len(data['test']))\n",
    "task = (data['test'][i]['instruction'] + '\\n' + data['test'][i]['input']).strip()\n",
    "prompt = f'### Задание: {task}\\n\\n### Ответ:'\n",
    "\n",
    "device = \"cuda:0\"\n",
    "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids = encoding.input_ids,\n",
    "        attention_mask = encoding.attention_mask,\n",
    "        **generation_params,\n",
    "    )\n",
    "pred_text = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50065016-e188-41fd-983a-760a7819f0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('### Задание: Вам представлено литературное произведение и его автор. Расскажите кратко о сюжете произведения.\\n\"Война и мир\" Льва Толстого.\\n\\n### Ответ:\\nВ романе \"Великая Отечественная война 1812 года\" (1969) Л.Н. Тольстой описывает события, происходившие в России в 25-м году жизни автора. В роман входят 5 книг, 49 глав, в которых описаны социальные, политические и военные совершенно разные реалии. Роман написан в форме исторического родословца, повествующего о судьбах нескольких родов, охватывающих все слои общества',\n",
       " 270)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_text, i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2d879c-690f-416e-8132-04ae665089d2",
   "metadata": {},
   "source": [
    "## Few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41d239c1-1f08-4ed2-bb4f-ed3f1e9a0c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Task: Расскажи о своей любимой книге, почему ты ее любишь, что особенного в ней для тебя.\n",
      "### Input: Любимая книга: Маленький принц\n",
      "Output: Моя любимая книга - \"Маленький принц\" Антуана де Сент-Экзюпери. Это история о маленьком принце с другой планеты, который отправился на поиски друзей и мудрости. Я люблю эту книгу, потому что она наполнена волшебством и глубокими философскими мыслями, которые касаются жизни, дружбы, любви и человеческих отношений. Особенное для меня в этой книге то, что, несмотря на то, что она изначально написана для детей, она подходит для людей всех возрастов, поскольку содержит уроки и прозрения, актуальные для каждого из нас в любом возрасте. Книга учит нас ценить маленькие радости жизни, взаимоотношения, и что искренность и бескорыстность - самые важные ценности.\n",
      "-----------------------------\n",
      "### Task: Преобразуй следующую дату в человеко-читаемый формат: день недели, число, месяц, год.\n",
      "### Input: 2023-08-12\n",
      "Output: Суббота, 12 августа 2023 года\n",
      "-----------------------------\n",
      "### Task: Сравните между собой два предмета по заданным параметрам.\n",
      "### Input: Предметы: лампа накаливания и светодиодная лампа. Параметры: эффективность, долговечность и воздействие на окружающую среду.\n",
      "Output: В сравнении с лампой накаливания, светодиодная лампа обладает более высокой эффективностью, долговечностью и меньшим воздействием на окружающую среду.\n",
      "-----------------------------\n",
      "### Task: Опиши причины и последствия Загадочного случая с локомоночником.\n",
      "### Input: Он пришел в бар один, покупал выпивку только себе, и все время что-то нашептывал.\n",
      "Output: Загадочный случай с локомоночником начался с того, что мужчина пришел в бар один, заказывал напитки только для себя и постоянно что-то нашептывал. Возможно, он был под страхом или переживал стресс, в результате чего странно вел себя и привлек к себе внимание окружающих. Последствия этого могут быть разными, вплоть до вмешательства полиции или заботливого поступка прохожих, пытающихся выяснить, что случилось и предложить помощь.\n",
      "-----------------------------\n",
      "### Task: Расскажите о концертных залах и видах мероприятий, которые можно провести в них.\n",
      "### Input: Название: Дом Музыки; Местоположение: Санкт-Петербург.\n",
      "Output: Дом Музыки в Санкт-Петербурге – это современный концертный комплекс, предлагающий разнообразные залы для проведения самых разных мероприятий. Здесь можно организовать концерты классической, джазовой, рок- или поп-музыки, а также провести театральные постановки, танцевальные шоу и многое другое. Благодаря уникальной архитектуре и отличной акустике, любое мероприятие в Доме Музыки станет незабываемым для зрителей и участников.\n",
      "-----------------------------\n",
      "### Task: Ответьте на вопрос о причинах колебаний количества жителей Земли в течение истории человечества.\n",
      "### Input: \n",
      "Output: Колебания количества жителей Земли в течение истории связаны с множеством факторов, таких как изменения в климате, миграции, болезни, войны, изменения в питании и технологиях, а также уровень образования и доступность медицинских услуг.\n",
      "-----------------------------\n",
      "### Task: Дай определение и примеры из жизни для психологического термина \"конформизм\".\n",
      "### Input: \n",
      "Output: Конформизм - это психологическое явление, когда индивид приспосабливается к поведению и мнениям группы, даже если это противоречит его личным убеждениям. Примеры из жизни: 1) подросток, который начинает курить, чтобы быть принятым в компанию сверстников; 2) сотрудник, который соглашается с непопулярным решением начальника, чтобы не выделяться и избежать конфликтов на работе.\n",
      "-----------------------------\n",
      "### Task: Составь текст объявления для продажи автомобиля.\n",
      "### Input: Модель: Toyota Corolla. Год выпуска: 2014. Пробег: 75 000 км. Цена: 600 000 рублей. Комплектация: электропривод зеркал, климат-контроль, круиз-контроль, парктроник, подогрев сидений.\n",
      "Output: Продаю Toyota Corolla 2014 года выпуска с пробегом 75 000 км, в отличном состоянии. Автомобиль оснащен: электроприводом зеркал, климат-контролем, круиз-контролем, парктроником и подогревом сидений. Цена: 600 000 рублей. Если вам нужен надежный, экономичный автомобиль с прекрасной комплектацией, то это предложение для вас! Звоните и приходите смотреть автомобиль.\n",
      "-----------------------------\n",
      "### Task: Напиши стихотворение на основе предложенного тематического слова.\n",
      "### Input: зима\n",
      "Output: Зима, зима, волшебница,\n",
      "Сквозь снег и мороз блещешь,\n",
      "Приносишь снегопады, праздники,\n",
      "В город и деревню тишина влечешь.\n",
      "-----------------------------\n",
      "### Task: Используя поставленные слова, составьте одно сложное предложение.\n",
      "### Input: компьютер, рабочий стол, документы, печать\n",
      "Output: На рабочем столе стоял компьютер, на котором были открыты важные документы, готовые для печати.\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    tmp = data[\"train\"][i]\n",
    "    print(generate_prompt(tmp))\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0242a2e4-396a-42af-a474-eff56bdd0652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'На рабочем столе стоял компьютер, на котором были открыты важные документы, готовые для печати.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_prompt = generate_prompt(tmp)\n",
    "ex_prompt[ex_prompt.find(\"Output: \") + 8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0ff8906-a394-4bae-9f00-3cc3cd5b5af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'instruction': (self.data[idx]['instruction'] + '\\n' + self.data[idx]['input']).strip(),\n",
    "            'output': self.data[idx]['output'].strip()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af8d99c6-62c1-493f-86fb-3183d643b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    inputs, outputs = [], []\n",
    "    \n",
    "    for x in data:\n",
    "        inp = f'### Задание: {x[\"instruction\"]}\\n\\n### Ответ:'\n",
    "        input_ids = tokenizer(\n",
    "            inp,\n",
    "            add_special_tokens=True\n",
    "        )['input_ids']\n",
    "        label_ids = tokenizer(\n",
    "            x['output'] + tokenizer.eos_token,\n",
    "            add_special_tokens=False,\n",
    "            max_length=512,\n",
    "            truncation=True\n",
    "        )['input_ids']\n",
    "        inputs.append(torch.tensor(input_ids + label_ids))\n",
    "        outputs.append(torch.tensor([-100] * len(input_ids) + label_ids))\n",
    "        \n",
    "    input_ids = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(outputs, batch_first=True, padding_value=-100)\n",
    "        \n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'labels': labels,\n",
    "        'attention_mask': input_ids.ne(0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fff6c7b8-8bb2-43c8-a6f3-8ab7e7ca50d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3000 examples should be enough for 7b model\n",
    "train_dataset = Dataset([data['train'][i] for i in range(3000)])\n",
    "train_dataset = Dataset(data['train'])\n",
    "eval_dataset = Dataset(data['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adef136e-4296-4ac8-bb42-83c1dbe34a32",
   "metadata": {},
   "source": [
    "# Metrics setup and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1f0f497-53ba-4e0d-80a6-0a6226ce0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import nltk\n",
    "\n",
    "metric = evaluate.load('rouge')\n",
    "def rouge_bleu_custom(pred):\n",
    "    references = pred.label_ids\n",
    "    predictions = pred.predictions[0]\n",
    "\n",
    "    ref_sent = []\n",
    "    pred_sent = []\n",
    "    macro_bleu = 0\n",
    "    for ref, predicted in zip(references, predictions):\n",
    "        # replace -100 with pad token\n",
    "        ref[ref == -100] = tokenizer.eos_token_id\n",
    "        ref_decoded = tokenizer.decode(ref, skip_special_tokens=True)\n",
    "        predicted[predicted == -100] = tokenizer.eos_token_id\n",
    "        predicted_decoded = tokenizer.decode(predicted, skip_special_tokens=True)\n",
    "        ref_sent.append(ref_decoded)\n",
    "        pred_sent.append(predicted_decoded)\n",
    "        \n",
    "        bleu_score = nltk.translate.bleu_score.sentence_bleu(\n",
    "                [ref_decoded],\n",
    "                predicted_decoded,\n",
    "                weights = [0.334, 0.333, 0.333]\n",
    "        )\n",
    "        macro_bleu += bleu_score\n",
    "    metrics_dict = metric.compute(predictions=pred_sent, references=ref_sent)\n",
    "    metrics_dict['bleu'] = macro_bleu / len(references)\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b9c3597-e4a7-4920-bc8d-336e97e72a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    \"\"\"\n",
    "    Original Trainer may have a memory leak. \n",
    "    This is a workaround to avoid storing too many tensors that are not needed.\n",
    "    \"\"\"\n",
    "\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    return pred_ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f765e816-db25-4ebf-8d89-9b1d6c58b4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='602' max='602' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [602/602 2:14:10, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.931100</td>\n",
       "      <td>0.835708</td>\n",
       "      <td>0.191417</td>\n",
       "      <td>0.123226</td>\n",
       "      <td>0.190067</td>\n",
       "      <td>0.189545</td>\n",
       "      <td>0.535177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=602, training_loss=0.9233396827580524, metrics={'train_runtime': 8065.0369, 'train_samples_per_second': 1.792, 'train_steps_per_second': 0.075, 'total_flos': 1.7911450183901184e+17, 'train_loss': 0.9233396827580524, 'epoch': 1.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "      per_device_train_batch_size=6,\n",
    "      per_device_eval_batch_size=1,\n",
    "      gradient_accumulation_steps=4,\n",
    "      eval_accumulation_steps=4,\n",
    "      num_train_epochs=1,\n",
    "      learning_rate=2e-4,\n",
    "      fp16=True,\n",
    "      save_total_limit=5,\n",
    "      output_dir=\"experiments\",\n",
    "      optim=\"paged_adamw_8bit\",\n",
    "      lr_scheduler_type=\"cosine\",\n",
    "      warmup_ratio=0.05,\n",
    "      logging_dir = './logs',\n",
    "      report_to = 'tensorboard',\n",
    "      load_best_model_at_end = True,\n",
    "      evaluation_strategy ='epoch',\n",
    "      eval_steps=5,\n",
    "      logging_strategy='steps',\n",
    "      logging_steps=1,\n",
    "      save_strategy='epoch',\n",
    "      save_steps=2000,\n",
    "      seed=SEED,\n",
    "      remove_unused_columns=False,\n",
    "      gradient_checkpointing=True,\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=rouge_bleu_custom,\n",
    "    data_collator=collate_fn,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e2b34-14bc-41e4-b103-2a3b80e863a0",
   "metadata": {},
   "source": [
    "## Check Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afb9f494",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alm/miniforge3/envs/assistant_nlp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import bitsandbytes as bnb\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "# using the style for the plot \n",
    "plt.style.use('dark_background') \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d970b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    load_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79fcbb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:45<00:00, 22.63s/it]\n"
     ]
    }
   ],
   "source": [
    "PEFT_MODEL = \"../models/mistral_7b\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(PEFT_MODEL)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    return_dict=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa8f40e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model, PEFT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21d1b59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alm/miniforge3/envs/assistant_nlp/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for lksy/ru_instruct_gpt4 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/lksy/ru_instruct_gpt4\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"lksy/ru_instruct_gpt4\", split=\"train\")\n",
    "data = data.train_test_split(test_size=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fda0e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.702e+03, 4.742e+03, 3.760e+03, 1.062e+03, 1.530e+02, 2.600e+01,\n",
       "        6.000e+00, 1.000e+00, 0.000e+00, 1.000e+00]),\n",
       " array([1.0000e+00, 1.9370e+02, 3.8640e+02, 5.7910e+02, 7.7180e+02,\n",
       "        9.6450e+02, 1.1572e+03, 1.3499e+03, 1.5426e+03, 1.7353e+03,\n",
       "        1.9280e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_len = []\n",
    "\n",
    "for i in range(len(data['train'])):\n",
    "    output_len.append(len(data['train'][i][\"output\"]))\n",
    "plt.hist(output_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aa5d221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of Train Output Len: 297.0\n",
      "Mean of Train Output Len: 306.17\n"
     ]
    }
   ],
   "source": [
    "print(f\"Median of Train Output Len: {np.median(output_len)}\")\n",
    "print(f\"Mean of Train Output Len: {np.mean(output_len):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d965e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры для генерации\n",
    "generation_params = {\n",
    "    \"max_new_tokens\": 300,\n",
    "    \"num_beams\": 3,\n",
    "    \"early_stopping\": True,\n",
    "    \"no_repeat_ngram_size\": 2,\n",
    "    \"eos_token_id\": tokenizer.eos_token_id,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d755a9dc",
   "metadata": {},
   "source": [
    "## Рассмотрим обработку текстов из валидационного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bf0c180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Задание: Сравни 3 типа образовательных учреждений по следующим критериям: возраст обучающихся, основная цель обучения, продолжительность обучения.\n",
      "- Детский сад\n",
      "- Школа\n",
      "- Университет\n",
      "\n",
      "### Ответ: - В детском саду обычно учатся дети от 2 до 7 лет. Основные цели - развитие физических, когнитивных и эмоциональных навыков, адаптация к общественному окружению. Программа длится 1-2 года, в зависимости от страны и системы образования, и включает в себя различные виды деятельности, такие как игры, пение, рисование и общая подготовка к школьной жизни. - Школы предназначены для детей и подростков от младших классов до старших. Целью является получение основных знаний в разных дисциплинах, формирование индивидуального мышления и умения анализировать информацию. Обучение в школе проходит на протяжении 9-11 лет и заканчивается выпускным экзаменом, необходимым для поступния в высшее учебное заведение или профессиональное образование. В некоторых странах существуют средние специальные школы, предлагающие специализи\n",
      "---------------------------------\n",
      "Оригинальный ответ: - Детский сад: возраст обучающихся - 3-7 лет, основная цель - развитие основных навыков и адаптация к социальной среде, продолжительность обучения - 2-4 года.\n",
      "- Школа: возраст обучающихся - 6/7-17/18 лет, основная цель - получение среднего общего образования и развитие индивидуальных способностей, продолжительность обучения - 9-11 лет.\n",
      "- Университет: возраст обучающихся - обычно с 18 лет, основная цель - получение профессионального высшего образования и развитие научно-исследовательских навыков, продолжительность обучения - от 4 лет и выше в зависимости от специальности и учебной степени.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Сформулируй вопрос на английском языке к данному предложению: Студенты собрались, чтобы обсудить изменения в образовательном процессе.\n",
      "Студенты собрались, чтобы обсудить изменения в образовательном процессе.\n",
      "\n",
      "### Ответ: Why did the students gather to discuss changes in the educational process?\n",
      "---------------------------------\n",
      "Оригинальный ответ: What changes in the educational process did the students gather to discuss?\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Используя названия геометрических фигур, охарактеризуй человека по имени Алексей.\n",
      "Алексей\n",
      "\n",
      "### Ответ: Его лицо было прямоугольным, а его тело - круглым, что говорило о его уравновешенности и гармонии.\n",
      "---------------------------------\n",
      "Оригинальный ответ: Алексей - стойкий, как куб, его душа кругла и полна радости, а мысли - острые, словно треугольник, при этом он способен быть таким гибким и многогранным, как параллелепипед.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Напиши аннотацию к сказке \"Золушка\" в двух предложениях.\n",
      "Золушка\n",
      "\n",
      "### Ответ: Сказка о прекрасной девушке, которую злая мачеха и сводные сестры превратили в прислугу, но благодаря доброй волшебнице стала принцессой и жила долго и счастливо.\n",
      "---------------------------------\n",
      "Оригинальный ответ: Золушка - обиженная и угнетаемая своей злой мачехой и сводными сестрами девушка, чья жизнь меняется, когда случайно попадает на королевский бал. Благодаря доброй волшебнице и своей доброте, Золушка находит свою любовь - прекрасного принца - и живет долго и счастливо.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Расскажи о влиянии пониженного атмосферного давления на состояние человека.\n",
      "\n",
      "### Ответ: Низкое погодное или авиационное давяние может вызывать различные симптомы, такие как головная боль, слабость, усталость и нарушение сна. Это происходит из-за снижения количества кислорода, доступного для дыхания, что приводит к уменьшению концентрации гемоглобина в крови и увеличению частоты сердечных сокращений.\n",
      "---------------------------------\n",
      "Оригинальный ответ: Пониженное атмосферное давление может оказывать различное воздействие на человека в зависимости от степени понижения и индивидуальных особенностей. Во время воздушных или горных поездок люди могут испытывать легкое недомогание, головную боль, утомление, нарушение сна и пищеварения. Это связано с меньшим количеством кислорода, доступного для дыхания, и снижением атмосферного давления на тело, что может приводить к образованию газов в крови и тканях, вызывая такие явления, как кавернозный газообразование.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Изложите основные положения теории Дарвина об эволюции видов.\n",
      "\n",
      "### Ответ: Теория эvolуции Чарльза Дарина предполагает, что виды происходят от общего предка и развиваются в результате естественного отбора, который выбирает наиболее приспособленных особей для выживания и размножения. Это приводит к постепенному изменению популяций и, в конечном итоге, к формированию новых и исчезновению других.\n",
      "---------------------------------\n",
      "Оригинальный ответ: Теория Дарвина об эволюции видов состоит из основных положений, таких как борьба за существование, естественный отбор и наследственность. Борьба за существование заключается в конкуренции между особями за ресурсы и выживание. Естественный отбор - процесс, в результате которого наиболее приспособленные к окружающей среде особи имеют больше шансов выжить и оставить потомство. Наследственность предполагает передачу унаследованных свойств от родителей к потомству, что позволяет выживать и преуспевать особям с более благоприятными характеристиками.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Вспомни известный поговорок или пословицу, используя предложенные слова в качестве ключевых\n",
      "гости, стол\n",
      "\n",
      "### Ответ: На гостеприимном столе всегда есть место.\n",
      "---------------------------------\n",
      "Оригинальный ответ: На нашем гостеприимном столе всегда хлеб-соль не обманешь.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Расскажи о знаменитом событии, связанном с представителем знати России в XVII-XVIII веках.\n",
      "Петр I, реформы, санкт-петербург, доступ к балтике\n",
      "\n",
      "### Ответ: В 1697 году Петр Великий основал город Санкт Петербурга, который впоследствии стал столицей Российской империи. Строительство города было связано с реформами, проводимыми Петром, направленными на модернизацию страны и укрепление ее международного положения. Основной целью решений Петра было предоставление России доступа к Балтийскому морю, что способствовало развитию торговли, военного дела и культурного обмена.\n",
      "---------------------------------\n",
      "Оригинальный ответ: Петр I, известный своим реформаторским духом, был ключевой фигурой в XVII-XVIII веках в России. Одним из самых значимых событий того времени стало основание Санкт-Петербурга в 1703 году. Строительство нового города обеспечило России выход к Балтийскому морю, укрепило политическое и экономическое влияние страны, а также стало ярким символом западной модернизации и прогресса.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Скажите нам о психологическом эффекте возвращения из долгосрочного путешествия в родной город.\n",
      "\n",
      "### Ответ: Возвращаясь из длительной поездки, люди могут испытывать чувство смешанных эмоций, таких как радость от встречи с друзьями и семьей, но также горечь по поводу изменений в окружающем мире. Это может вызвать ощущение непривычности и незнакомости, что в свою очередь приводит к стрессу и адаптационным проблемам.\n",
      "---------------------------------\n",
      "Оригинальный ответ: При возвращении из долгосрочного путешествия в родной город люди могут испытывать смешанные эмоции, такие как радость от встречи с друзьями и семьей, ощущение дежавю и непривычности привычных мест, а также меланхолия по прошедшим приключениям и ностальгия по новым друзьям и странам, которые они покинули.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Опиши ключевые события Великой Отечественной войны с 1941 по 1945 годы.\n",
      "\n",
      "### Ответ: - 22.06-23.12 44 г. - Битва за Москву\n",
      "- 09-10.7.42 - Операция \"Блау\" (Барбаросса) - наступление Германии на Советский Западный фронт, крупнейшее наземное сражение в истории по числу принимающих участие войск и территории, на которую оно распространялось.\n",
      "---------------------------------\n",
      "Оригинальный ответ: В 1941 году началась Великая Отечественная война - 22 июня нацистская Германия напала на СССР. В 1942 году состоялась Битва за Москву, закончившаяся отступлением немецких войск. В 1943 году прошла битва на Курской дуге, ставшая поворотным моментом войны в пользу СССР. В 1944 году произошло освобождение множества территорий от фашистских захватчиков. В 1945 году Красная армия освободила Восточную Европу и взяла Берлин, что привело к капитуляции нацистской Германии и окончанию Великой Отечественной войны 9 мая.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_data = data['test']\n",
    "\n",
    "for _ in range(10):\n",
    "  i = np.random.randint(len(val_data))\n",
    "  task = (val_data[i]['instruction'] + '\\n' + val_data[i]['input']).strip()\n",
    "  prompt = f'### Задание: {task}\\n\\n### Ответ:'\n",
    "  original_prompt = f'### Задание: {task}\\n\\n### Ответ:'\n",
    "  original_prompt += val_data[i]['output']\n",
    "\n",
    "  device = \"cuda:0\"\n",
    "  encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "  with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids = encoding.input_ids,\n",
    "        attention_mask = encoding.attention_mask,\n",
    "        **generation_params,\n",
    "  )\n",
    "  pred_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "  # sequence_start = pred_text.find(\"Output: \") + 8\n",
    "  print(pred_text)\n",
    "  print(\"---------------------------------\")\n",
    "  print(\"Оригинальный ответ: \" + val_data[\"output\"][i])\n",
    "  print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
