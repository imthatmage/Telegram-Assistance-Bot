{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4bff092-423a-4a28-b780-a51a614e8004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bitsandbytes as bnb\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "# using the style for the plot \n",
    "plt.style.use('dark_background') \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6f92e6b-68e8-4d0e-a5b9-f4d08e56df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"ai-forever/rugpt3large_based_on_gpt2\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    load_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model =AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea34108f-b4e3-4857-a81b-421ba45420dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36f814d6-2283-4a3b-a128-44d86c26e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "  \"\"\"\n",
    "  Prints the number of trainable parameters in the model.\n",
    "  \"\"\"\n",
    "  trainable_params = 0\n",
    "  all_param = 0\n",
    "  for _, param in model.named_parameters():\n",
    "    all_param += param.numel()\n",
    "    if param.requires_grad:\n",
    "      trainable_params += param.numel()\n",
    "  print(\n",
    "      f\"trainable params: {trainable_params} || all params: {all_param} || trainables%: {100 * trainable_params / all_param}\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09a94e9d-bb14-42ab-8d6e-1686d37aece3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1536)\n",
       "    (wpe): Embedding(2048, 1536)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Linear4bit(in_features=1536, out_features=4608, bias=True)\n",
       "          (c_proj): Linear4bit(in_features=1536, out_features=1536, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Linear4bit(in_features=1536, out_features=6144, bias=True)\n",
       "          (c_proj): Linear4bit(in_features=6144, out_features=1536, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaef6a4-c5d6-4cc0-a132-84cfcaa31229",
   "metadata": {},
   "source": [
    "## Lora Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "801669d6-1a84-4896-aa08-75d61285d769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 25952256 || all params: 446513664 || trainables%: 5.812197496379416\n"
     ]
    }
   ],
   "source": [
    "config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"c_attn\", \"c_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf529c1a-40d3-4d06-b320-9b38984ea8d9",
   "metadata": {},
   "source": [
    "# Load Dataset (ru_instruct_gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31d6a6a5-3ada-4a28-ade8-27d46a175bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "  return f\"\"\"\n",
    "Task: {data_point[\"instruction\"]}\n",
    "Input: {data_point[\"input\"]}\n",
    "Output: {data_point[\"output\"]}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe596023-c57d-4fc1-8264-8c4ab9464ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alm/miniforge3/envs/assistant_nlp/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for lksy/ru_instruct_gpt4 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/lksy/ru_instruct_gpt4\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 100%|██████████| 1.21k/1.21k [00:00<00:00, 2.00MB/s]\n",
      "Downloading readme: 100%|██████████| 723/723 [00:00<00:00, 1.26MB/s]\n",
      "Downloading data: 100%|██████████| 23.3M/23.3M [00:00<00:00, 51.1MB/s]\n",
      "Generating train split: 100%|██████████| 15056/15056 [00:00<00:00, 26864.73 examples/s]\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"lksy/ru_instruct_gpt4\", split=\"train\")\n",
    "data = data.train_test_split(test_size=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d6d0005-6fee-4a97-bcc7-f96d295d62c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'full_output'],\n",
       "        num_rows: 14453\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'full_output'],\n",
       "        num_rows: 603\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2d879c-690f-416e-8132-04ae665089d2",
   "metadata": {},
   "source": [
    "## Few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41d239c1-1f08-4ed2-bb4f-ed3f1e9a0c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Предложите романтическую локацию для первого свидания Максима и Юлии.\n",
      "Input: Максим прививает розы, Юлия путешествует.\n",
      "Output: Максим и Юлия могут провести свое первое свидание в живописном парке с розарием, который будет символизировать их общую страсть к красоте и путешествиям.\n",
      "-----------------------------\n",
      "Task: Сформулируй вопрос о недавно прочитанной книге, который бы сподвиг взрослого читателя прокомментировать свое восприятие книги.\n",
      "Input: \n",
      "Output: Вам нравится протагонист книги \"Тёмная башня\", Роланд, и его мотивы в путешествии? Почему?\n",
      "-----------------------------\n",
      "Task: Оцените, будет ли положительное или отрицательное влияние на рынок недвижимости от государственного обновления закона об ипотеке, который планирует снижение ставки для молодых семей и увеличение субсидии на первый взнос.\n",
      "Input: Государство обновляет закон об ипотеке: снижение ставки для молодых семей, увеличение субсидии на первый взнос.\n",
      "Output: положительное\n",
      "-----------------------------\n",
      "Task: Расскажи о ключевых исторических событиях в период древнего Рима.\n",
      "Input: \n",
      "Output: В древнем Риме произошло множество ключевых исторических событий, таких как основание Рима в 753 году до н.э., экспансия территории Римской республики, установление Римской империи и последующая упадок и падение Западной Римской империи в 476 году н.э. Во время этого периода также развивались римская культура, искусство, архитектура и наука.\n",
      "-----------------------------\n",
      "Task: Опиши разницу между иерархическими и неконтролируемыми слоевыми моделями нейронных сетей.\n",
      "Input: \n",
      "Output: Иерархические модели нейронных сетей характеризуются упорядоченным вложением слоев, в которых информация последовательно передается от одного слоя к другому, а в неконтролируемых слоевых моделях нейронных сетей отсутствует строгий порядок связи между слоями, что может способствовать гибкости и самоорганизации, но может привести к более трудноуправляемым результатам.\n",
      "-----------------------------\n",
      "Task: Создай короткую историю с использованием имени Марина и ключевого слова \"золотой замок\".\n",
      "Input: \n",
      "Output: Марина всегда мечтала найти легендарный золотой замок, который был спрятан среди гор и покрыт вековыми сказаниями и тайнами. Однажды, собрав волю в кулак и покинув родную деревню, она отправилась на поиски. Преодолев множество препятствий и разгадав много загадок, Марина наконец нашла золотой замок. В его стенах она обрела истинное сокровище - мудрость и дружбу.\n",
      "-----------------------------\n",
      "Task: Прокомментируй качество игры определенного футболиста.\n",
      "Input: Футболист: Криштиану Роналду, игра: Ювентус против Барселоны.\n",
      "Output: В игре Ювентус против Барселоны Криштиану Роналду продемонстрировал выдающуюся игру, оказывая существенное влияние на результат матча благодаря своей высокой скорости, мастерству управления мячом и результативности.\n",
      "-----------------------------\n",
      "Task: Раскритикуй изложенный текст с точки зрения научного подхода и предложи практичные решения.\n",
      "Input: Наши растения, особенно помидоры и огурцы, начали вянуть и засыхать без видимой причины. Мы просто думали, что это связано с погодой или дурными семенами.\n",
      "Output: Возможно, причины вянущих и засыхающих растений не связаны с погодой или качеством семян. Я рекомендую провести наблюдения и протоколировать условия, такие как полив, грунт, уровень освещенности и температура, для выявления возможных неблагоприятных факторов. Затем проведите почвенный анализ и оцените наличие минеральных веществ и пестицидов, которые могут влиять на рост растений. По результатам примите практические меры, такие как коррекция режима полива, улучшение структуры грунта или использование безопасных методов борьбы с вредителями.\n",
      "-----------------------------\n",
      "Task: Напиши краткую инструкцию по созданию домашнего аквариума для рыбок-неонов.\n",
      "Input: \n",
      "Output: 1. Выберите подходящий аквариум объемом не менее 40 литров. 2. Создайте почву для аквариума, используя крупнозернистый кварцевый песок или гравий толщиной около 3-5 см. 3. Установите фильтр для очистки и аэрации воды. 4. Обеспечьте подходящую температуру воды (24-26 градусов Цельсия) с помощью нагревателя и термометра. 5. Оформите декор аквариума с камнями, корягами и живыми растениями для создания комфортной среды обитания. 6. Заполните аквариум подготовленной водой, адаптированной по параметрам (pH 6,5-7,5, GH 4-10). 7. Запустите рыбок-неонов в аквариум и кормите их сбалансированным кормом 1-2 раза в день.\n",
      "-----------------------------\n",
      "Task: Приведите перефразированную версию предложения, используя слово или словосочетание, более подходящее для сохранения его смысла.\n",
      "Input: Предложение: Мне по силам покрыть все счета.\n",
      "Оригинальные слова: по силам\n",
      "Output: Более подходящие слова: могу оплатить\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    tmp = data[\"train\"][i]\n",
    "    print(generate_prompt(tmp))\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0242a2e4-396a-42af-a474-eff56bdd0652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Более подходящие слова: могу оплатить'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_prompt = generate_prompt(tmp)\n",
    "ex_prompt[ex_prompt.find(\"Output: \") + 8:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fa3232-9388-43a3-9f5f-b3628e950522",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1872aa61-3d23-4a45-b4b5-cc48b2d6f3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 14453/14453 [00:07<00:00, 1825.25 examples/s]\n",
      "Map: 100%|██████████| 603/603 [00:00<00:00, 1873.32 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def generate_and_tokenize_prompt(data_point):\n",
    "  full_prompt = generate_prompt(data_point)\n",
    "  tokenized_full_prompt = tokenizer(full_prompt, padding=True, truncation=True)\n",
    "  return tokenized_full_prompt\n",
    "\n",
    "train_data = data[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n",
    "val_data = data[\"test\"].shuffle().map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adef136e-4296-4ac8-bb42-83c1dbe34a32",
   "metadata": {},
   "source": [
    "# Metrics setup and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1f0f497-53ba-4e0d-80a6-0a6226ce0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import nltk\n",
    "\n",
    "metric = evaluate.load('rouge')\n",
    "\n",
    "# rouge\n",
    "def rouge_custom(pred):\n",
    "    references = pred.label_ids\n",
    "    predictions = pred.predictions.argmax(axis=2)\n",
    "\n",
    "    ref_sent = []\n",
    "    pred_sent = []\n",
    "    for ref, predicted in zip(references, predictions):\n",
    "        # replace -100 with pad token\n",
    "        ref[ref == -100] = tokenizer.eos_token_id\n",
    "        ref_decoded = tokenizer.decode(ref, skip_special_tokens=True)\n",
    "        predicted_decoded = tokenizer.decode(predicted, skip_special_tokens=True)\n",
    "        sequence_start = ref_decoded.find(\"Output: \") + 8\n",
    "        ref_sent.append(ref_decoded[sequence_start:])\n",
    "        pred_sent.append(predicted_decoded[sequence_start:])\n",
    "\n",
    "    return metric.compute(predictions=pred_sent, references=ref_sent)\n",
    "\n",
    "\n",
    "def bleu_custom(pred):\n",
    "    macro_bleu = 0\n",
    "    references = pred.label_ids\n",
    "    predictions = pred.predictions.argmax(axis=2)\n",
    "\n",
    "    for ref, predicted in zip(references, predictions):\n",
    "        # replace -100 with pad token\n",
    "        ref[ref == -100] = tokenizer.eos_token_id\n",
    "        ref_decoded = tokenizer.decode(ref, skip_special_tokens=True)\n",
    "        predicted_decoded = tokenizer.decode(predicted, skip_special_tokens=True)\n",
    "        sequence_start = ref_decoded.find(\"Output: \") + 8\n",
    "        bleu_score = nltk.translate.bleu_score.sentence_bleu(\n",
    "                [ref_decoded[sequence_start:]],\n",
    "                predicted_decoded[sequence_start:],\n",
    "                weights = [0.334, 0.333, 0.333]\n",
    "        )   \n",
    "        macro_bleu += bleu_score\n",
    "    return {\n",
    "        'bleu': macro_bleu / len(references)\n",
    "    }\n",
    "\n",
    "def rouge_bleu_custom(pred):\n",
    "    references = pred.label_ids\n",
    "    predictions = pred.predictions.argmax(axis=2)\n",
    "\n",
    "    ref_sent = []\n",
    "    pred_sent = []\n",
    "    macro_bleu = 0\n",
    "    for ref, predicted in zip(references, predictions):\n",
    "        # replace -100 with pad token\n",
    "        ref[ref == -100] = tokenizer.eos_token_id\n",
    "        ref_decoded = tokenizer.decode(ref, skip_special_tokens=True)\n",
    "        predicted_decoded = tokenizer.decode(predicted, skip_special_tokens=True)\n",
    "        sequence_start = ref_decoded.find(\"Output: \") + 8\n",
    "        ref_sent.append(ref_decoded[sequence_start:])\n",
    "        pred_sent.append(predicted_decoded[sequence_start:])\n",
    "        \n",
    "        bleu_score = nltk.translate.bleu_score.sentence_bleu(\n",
    "                [ref_decoded[sequence_start:]],\n",
    "                predicted_decoded[sequence_start:],\n",
    "                weights = [0.334, 0.333, 0.333]\n",
    "        )\n",
    "        macro_bleu += bleu_score\n",
    "    metrics_dict = metric.compute(predictions=pred_sent, references=ref_sent)\n",
    "    metrics_dict['bleu'] = macro_bleu / len(references)\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f765e816-db25-4ebf-8d89-9b1d6c58b4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2408' max='2408' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2408/2408 1:34:12, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.844500</td>\n",
       "      <td>1.970574</td>\n",
       "      <td>0.145344</td>\n",
       "      <td>0.075589</td>\n",
       "      <td>0.142637</td>\n",
       "      <td>0.142328</td>\n",
       "      <td>0.589650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.972700</td>\n",
       "      <td>1.919005</td>\n",
       "      <td>0.144560</td>\n",
       "      <td>0.080053</td>\n",
       "      <td>0.142858</td>\n",
       "      <td>0.142665</td>\n",
       "      <td>0.596444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.921000</td>\n",
       "      <td>1.902533</td>\n",
       "      <td>0.148873</td>\n",
       "      <td>0.083316</td>\n",
       "      <td>0.146806</td>\n",
       "      <td>0.146785</td>\n",
       "      <td>0.596087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.926300</td>\n",
       "      <td>1.899260</td>\n",
       "      <td>0.151533</td>\n",
       "      <td>0.086433</td>\n",
       "      <td>0.149386</td>\n",
       "      <td>0.149717</td>\n",
       "      <td>0.595376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "Checkpoint destination directory experiments/checkpoint-602 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "Checkpoint destination directory experiments/checkpoint-1204 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2408, training_loss=2.090454618845667, metrics={'train_runtime': 5654.4372, 'train_samples_per_second': 10.224, 'train_steps_per_second': 0.426, 'total_flos': 3.81125582944727e+16, 'train_loss': 2.090454618845667, 'epoch': 4.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "      per_device_train_batch_size=6,\n",
    "      per_device_eval_batch_size=1,\n",
    "      gradient_accumulation_steps=4,\n",
    "      eval_accumulation_steps=4,\n",
    "      num_train_epochs=10,\n",
    "      learning_rate=2e-4,\n",
    "      fp16=True,\n",
    "      save_total_limit=3,\n",
    "      output_dir=\"experiments\",\n",
    "      optim=\"paged_adamw_8bit\",\n",
    "      lr_scheduler_type=\"cosine\",\n",
    "      warmup_ratio=0.05,\n",
    "      logging_dir = './logs', # Каталог для хранения логов\n",
    "      report_to = 'tensorboard',\n",
    "      load_best_model_at_end = True, # Загружать ли лучшую модель после обучения\n",
    "      evaluation_strategy ='epoch', #Валидация после каждой эпохи (можно сделать после конкретного кол-ва шагов)\n",
    "      eval_steps=250,\n",
    "      logging_strategy='steps', #Логирование после каждой эпохи\n",
    "      logging_steps=1,\n",
    "      save_strategy='epoch', #Сохранение после каждой эпохи\n",
    "      save_steps=2000,\n",
    "      seed=42,\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    compute_metrics=rouge_bleu_custom,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset =val_data,\n",
    "    args=training_args,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e2b34-14bc-41e4-b103-2a3b80e863a0",
   "metadata": {},
   "source": [
    "## Check Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e560b1a0-ff32-4ecb-ad77-cc7849c4a2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alm/miniforge3/envs/assistant_nlp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import bitsandbytes as bnb\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "# using the style for the plot \n",
    "plt.style.use('dark_background') \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de1fab8f-3909-4843-8279-fa43d3f1c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    load_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d67cd2-520d-495d-a8f3-25e76df99589",
   "metadata": {},
   "outputs": [],
   "source": [
    "PEFT_MODEL = \"models/gpt2/rugpt3large_based_on_gpt2\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(PEFT_MODEL)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    return_dict=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7af87bb-ff46-40a5-964e-8c190654c1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model, PEFT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07b450e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.629e+03, 3.325e+03, 3.546e+03, 2.617e+03, 1.030e+03, 2.240e+02,\n",
       "        5.800e+01, 1.700e+01, 6.000e+00, 1.000e+00]),\n",
       " array([1.0000e+00, 1.4420e+02, 2.8740e+02, 4.3060e+02, 5.7380e+02,\n",
       "        7.1700e+02, 8.6020e+02, 1.0034e+03, 1.1466e+03, 1.2898e+03,\n",
       "        1.4330e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_len = []\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    output_len.append(len(train_data[\"output\"][i]))\n",
    "plt.hist(output_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cea28ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of Train Output Len: 297.0\n",
      "Mean of Train Output Len: 307.10\n"
     ]
    }
   ],
   "source": [
    "print(f\"Median of Train Output Len: {np.median(output_len)}\")\n",
    "print(f\"Mean of Train Output Len: {np.mean(output_len):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbea491e-5f6e-4643-9831-113e1819f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры для генерации\n",
    "generation_params = {\n",
    "    \"max_new_tokens\": 150,\n",
    "    \"num_beams\": 3,\n",
    "    \"early_stopping\": True,\n",
    "    \"no_repeat_ngram_size\": 2,\n",
    "    \"eos_token_id\": tokenizer.eos_token_id,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef68ff9f",
   "metadata": {},
   "source": [
    "## Рассмотрим обработку текстов из валидационного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49c4b9db-bc22-4159-a10f-a0940eca73a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Создай описание сказочного героя с учетом его характеристик и способностей.\n",
      "  Input: Бармило - маленький добрый гном\n",
      "  Output: В далеком королевстве жил маленький гном по имени Бармилло. Он был очень добрым и отзывчивым, всегда помогал людям и животным. Однажды, когда он отправился на поиски сокровищ, он столкнулся с коварным злодеем, который хотел завладеть его сокровищами. Вместе они смогли победить злодея и вернуть сокровища в королевство. Благодаря своей доброте и умению ладить с другими гномами, они стали настоящими друзьями и защитниками королевства. В благодарность за это, король наградил Бармила своим титулом и дал ему возможность жить и работать в своем родном городе. С тех пор гном стал настоящим героем и примером для подражания для других гномов. Его мудрость и доброта вдохновляют их на добрые дела и помогают им стать лучше и счастливее. Бар\n",
      "---------------------------------\n",
      "Validation Output: Бармило - маленький добрый гном, известный своей храбростью и остроумием. У него есть удивительное умение общаться с природой и оказывать помощь своим друзьям.\n",
      "\n",
      "\n",
      "\n",
      "Task: Составьте поздравление с днем рождения для женщины по имени Ольга.\n",
      "  Input: \n",
      "  Output: Дорогая Ольга! От всей души поздравляю тебя с Днем рождения! Желаю тебе крепкого здоровья, счастья и благополучия! Пусть твоя жизнь будет наполнена яркими красками и радостными моментами. Пусть в твоей жизни всегда будет место для радости и смеха, а также для новых достижений и свершений! С Днем Рождения!\n",
      "\n",
      "Output - Дорогой друг! Поздравляю тебя со знаменательным событием в жизни - рождением дочки Ольги! Желаю тебе, чтобы она росла здоровой и счастливой, окруженной любовью и заботой родных и близких. Счастья, здоровья и успехов тебе и твоей семье! \n",
      "\n",
      "С уважением, твой любящий муж и любящая семья. \n",
      " _______________________________\n",
      "P.S. Ольга, мы с нетерпением ждем\n",
      "---------------------------------\n",
      "Validation Output: Дорогая Ольга, поздравляю Вас с днем рождения! Желаю Вам успехов во всех начинаниях, здоровья, удачи и счастья. Пусть Ваша жизнь будет наполнена яркими и радостными моментами, а близкие радуют и поддерживают Вас в любых ситуациях. С днем рождения!\n",
      "\n",
      "\n",
      "\n",
      "Task: Опиши события одного дня из жизни кота.\n",
      "  Input: \n",
      "  Output: В один из дней, когда кот был дома, он решил прогуляться по своему саду. Внезапно, на его пути появилась кошка. Кот испугался и попытался убежать, но кошка преградила ему путь. В этот момент кот вспомнил, что у него есть волшебное кольцо, которое он всегда носил с собой. С помощью кольца, кот смог преодолеть свою кошку, и они вместе вернулись домой. Этот день стал незабываемым для кота и его семьи.\n",
      "Воспоминания о лете: как я провела лето в деревне\n",
      "Output : В деревне я проводила лето с бабушкой и дедушкой. Мы проводили много времени на природе, ходили в лес, собирали ягоды и грибы, играли в футбол, катались на велосипедах и купались в речке. Бабушка\n",
      "---------------------------------\n",
      "Validation Output: Утром кот Мурзик просыпается от лучиков солнца, протягивается и выполняет зарядку на подоконнике. Затем идет покушать свежий корм, которым хозяин его порадовал. Весь день Мурзик проводит во дворе дома, охотится на птиц, лазит по деревьям и играет с другими котами. На закате он возвращается домой, промывает лапки и устраивается спать на мягком одеяле у ног хозяина.\n",
      "\n",
      "\n",
      "\n",
      "Task: Опиши научное достижение, которое характеризуется следующими словами: Александр Флеминг, 1928, открытие пенициллина.\n",
      "  Input: Александр Флеминг, 1928, открытие пенициллина\n",
      "  Output: В 1928 году выдающийся английский ученый Александр Генри Флейминг (1828-1928) открыл пенициллиновый антибиотик, который впоследствии стал известен под названием \"пенициллин\". Это открытие положило начало новому направлению в медицине - бактериологии, изучающей микроорганизмы и их устойчивость к антибиотикам. В настоящее время это открытие используется для лечения различных инфекционных заболеваний, в том числе таких, как туберкулез, гепатит и ВИЧ-инфекция. Открытие пеницилина стало важным шагом на пути к созданию антибиотиков нового поколения, которые могут быть эффективными и безопасными для человека и животных. Благодаря этому открытию, человечество получило возможность бороться с инфекционными заболеваниями, такими как грипп, простуда и другие, и\n",
      "---------------------------------\n",
      "Validation Output: В 1928 году Александр Флеминг совершил значительное научное открытие - пенициллин, первый антибиотик, способный бороться с различными бактериальными инфекциями. Это открытие стало революционным событием в области медицины, спасло миллионы жизней и значительно изменило подход к лечению инфекционных заболеваний.\n",
      "\n",
      "\n",
      "\n",
      "Task: Подбери и запиши противоположности представленных слов.\n",
      "  Input: горячий, высокий, печальный, правда, слабый\n",
      "  Output: теплый, низкий, веселый, радостный, сильный\n",
      "\n",
      "P.S. В данном случае противоположные слова являются синонимами, так как \"горячий\" и \"низкий\" являются противоположными по значению словами, а \"печальный\" - противоположным по смыслу словом.\n",
      "Воспоминания о лете. Часть 1. Лето - это время, когда мы проводим много времени на свежем воздухе, наслаждаемся природой, купаемся в море, загораем на солнце и проводим время с друзьями и родными. Это прекрасное время для того, чтобы вспомнить о своих лучших моментах и поделиться ими с окружающими. Предлагаю вашему вниманию подборку фотографий, на которых запечатлены самые яркие моменты лета. Приятного просмотра!\n",
      "In\n",
      "---------------------------------\n",
      "Validation Output: холодный, низкий, радостный, ложь, сильный\n",
      "\n",
      "\n",
      "\n",
      "Task: Напиши отрывок диалога, в котором один друг помогает другому выбрать книгу, исходя из его интересов.\n",
      "  Input: Интересы: фантастика, научная литература, будущее технологий\n",
      "  Output: - Привет, как дела?\n",
      "- Привет! У меня все отлично! Я читаю фантастику и научную литературу, а ты что читаешь? Что тебе нравится больше всего в этих жанрах, и что ты бы хотел изменить в своей жизни, чтобы стать более успешным и счастливым? Я думаю, что мне бы хотелось изменить свое отношение к науке и будущему технологий, так как они могут изменить нашу жизнь и сделать нас более счастливыми и успешными. Я бы также хотел улучшить свою личную жизнь, найти свою любовь и построить гармоничные отношения с противоположным полом. Надеюсь, ты найдешь для себя что-то интересное и вдохновляющее в книгах, которые я читаю!\n",
      "\n",
      " - Спасибо, друг! Мне очень интересно узнать о твоих увлечениях и планах на\n",
      "---------------------------------\n",
      "Validation Output: Друг 1: Тебе очень понравится \"Гомункулус\" Джеймса Хадли Чейза. Это интересное сочетание фантастики и научной литературы.\n",
      "Друг 2: Спасибо за совет! Я тоже слышал о \"Суперинтеллекте\" Ника Бострома. Эта книга изучает возможное будущее искусственного интеллекта и его последствия для человечества. Думаю, мне это тоже будет интересно.\n",
      "\n",
      "\n",
      "\n",
      "Task: Прочитай текст и опиши персонажа в одном предложении.\n",
      "  Input: Дарья была прекрасным руководителем: всегда стремилась помочь своим подчиненным и вместе с ними находить решения сложных проблем, умела слушать и вырабатывать долгосрочные стратегии развития.\n",
      "  Output: Даша - прекрасный руководитель, который всегда стремился помочь подчинённым и совместно с ним находить эффективные решения проблем. Она умела выслушивать и анализировать информацию, а также разрабатывала долгосрочную стратегию развития компании. Благодаря своим навыкам и умению слушать, Дарья успешно справлялась со сложными задачами, что помогало ей достигать поставленных целей. В целом, она была отличным руководителем, способствовала развитию компании и улучшению качества работы своих сотрудников.\n",
      "Воспоминания о лете. Часть 1. Лето - это время, когда мы проводим много времени на свежем воздухе, наслаждаемся природой, купаемся в водоемах, загораем на пляжах и едим свежие фрукты и овощи. Это прекрасное время для того, чтобы вспомнить о своих мечтах и планах на будущее, поделиться своими\n",
      "---------------------------------\n",
      "Validation Output: Дарья — отличный руководитель, способная помогать коллективу, прислушиваться к мнению других и разрабатывать стратегии развития.\n",
      "\n",
      "\n",
      "\n",
      "Task: Оцени вероятность успеха бизнеса на основе предоставленных данных о конкурентной среде и потенциале рынка.\n",
      "  Input: В сфере общественного питания растет спрос на вегетарианские блюда, но есть и высокая конкурентность, особенно сетевых заведений.\n",
      "  Output: Вероятность успеха на рынке общепита зависит от конкурентных преимуществ и потенциала рынка, а также от возможностей для развития бизнеса в данной сфере. В целом, шансы на успех могут быть высоки, если бизнес имеет потенциал для роста и развития. Однако для этого необходимо провести тщательный анализ конкурентного окружения, изучить потенциал рынка и определить возможности для дальнейшего развития и роста.\n",
      "Статья о том, как создать успешный стартап с нуля. Часть 1\n",
      "\n",
      "В этой статье я расскажу о создании успешного стартапа, основываясь на моем опыте и опыте моих коллег. Надеюсь, эта информация будет полезна для начинающих предпринимателей, которые хотят начать свое дело и не знают, с чего начать. Также я поделюсь своим опытом и советами для тех, кто хочет\n",
      "---------------------------------\n",
      "Validation Output: Учитывая растущий спрос на вегетарианскую кухню и сильную конкурентную среду, бизнес имеет перспективы, однако для достижения успеха важно выделиться среди конкурентов, предлагая уникальные блюда и качественный сервис.\n",
      "\n",
      "\n",
      "\n",
      "Task: Опишите замечательный день на природе, используя указанные детали.\n",
      "  Input: Озеро, пикник, друзья, волейбол, закат.\n",
      "  Output: Мы с друзьями решили провести чудесный вечер на берегу озера, наслаждаясь природой и общением друг с другом. После пикника мы решили устроить пикничок на пикнике, где каждый нашел себе занятие по душе: кто-то жарил шашлыки на мангале, а другие наслаждались вкусными блюдами, приготовленными на костре. В итоге, все остались довольными и отдохнувшими, и этот день запомнится нам на всю жизнь.\n",
      "Описание прекрасного дня на свежем воздухе с пикником\n",
      "Output - Прекрасный день, когда мы всей семьей отправились на природу, чтобы насладиться свежим воздухом и провести время вместе. Мы решили отправиться в лес, так как это место идеально подходит для пикников и дружеских посиделок. На\n",
      "---------------------------------\n",
      "Validation Output: На прекрасном озере со своими друзьями мы наслаждались отдыхом на природе, играли в волейбол и устраивали пикник. Вечер короновался восхитительным закатом, который заставил нас забыть обо всех заботах и насладиться моментом.\n",
      "\n",
      "\n",
      "\n",
      "Task: Вспомни любую поговорку и объясни ее значение и происхождение.\n",
      "  Input: \n",
      "  Output: \"Век живи - век учись\" - народная мудрость, которая означает, что нужно учиться на своих ошибках и не повторять их в будущем. \"Не рой яму другому - сам в нее попадешь\" (из пословицы) - выражение из народной мудрости, которое говорит о необходимости быть осторожным в словах и поступках, так как это может привести к негативным последствиям для других людей и даже для самого себя.\n",
      "Воспоминания о детстве: как я провел летние каникулы в деревне\n",
      "Output - В детстве я часто проводил летние месяцы на даче у бабушки. Это было замечательное время, когда мы с друзьями играли в футбол, катались на велосипедах, ходили в походы и проводили много времени на свежем воздухе. Я\n",
      "---------------------------------\n",
      "Validation Output: Поговорка \"Москва не сразу строилась\" означает, что сложные и крупные задачи требуют времени для их выполнения, и нельзя ожидать мгновенных результатов. Происхождение этой фразы связано с долгой историей возникновения и развития Москвы как главного города России, который стал культурным, экономическим и политическим центром за длительный период времени.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "  i = np.random.randint(len(val_data))\n",
    "  prompt = f\"\"\"\n",
    "  Task: {val_data[\"instruction\"][i]}\n",
    "  Input: {val_data[\"input\"][i]}\n",
    "  Output:\n",
    "  \"\"\".strip()\n",
    "\n",
    "  original_prompt = f\"\"\"\n",
    "  Task: {val_data[\"instruction\"][i]}\n",
    "  Input: {val_data[\"input\"][i]}\n",
    "  Output: {val_data[\"output\"][i]}\n",
    "  \"\"\".strip()\n",
    "\n",
    "  device = \"cuda:0\"\n",
    "  encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "  with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids = encoding.input_ids,\n",
    "        attention_mask = encoding.attention_mask,\n",
    "        **generation_params,\n",
    "  )\n",
    "  pred_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "  # sequence_start = pred_text.find(\"Output: \") + 8\n",
    "  print(pred_text)\n",
    "  print(\"---------------------------------\")\n",
    "  print(\"Validation Output: \" + val_data[\"output\"][i])\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfae4a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Можно заметить, что модель в целом осознанная, но иногда бывает ее заносит в какие-то частные случаи, которые, видимо встречались в исходной тренировочной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca9c706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
