{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4bff092-423a-4a28-b780-a51a614e8004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bitsandbytes as bnb\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "# using the style for the plot \n",
    "plt.style.use('dark_background') \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6f92e6b-68e8-4d0e-a5b9-f4d08e56df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"ai-forever/rugpt3large_based_on_gpt2\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    load_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model =AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea34108f-b4e3-4857-a81b-421ba45420dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36f814d6-2283-4a3b-a128-44d86c26e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "  \"\"\"\n",
    "  Prints the number of trainable parameters in the model.\n",
    "  \"\"\"\n",
    "  trainable_params = 0\n",
    "  all_param = 0\n",
    "  for _, param in model.named_parameters():\n",
    "    all_param += param.numel()\n",
    "    if param.requires_grad:\n",
    "      trainable_params += param.numel()\n",
    "  print(\n",
    "      f\"trainable params: {trainable_params} || all params: {all_param} || trainables%: {100 * trainable_params / all_param}\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09a94e9d-bb14-42ab-8d6e-1686d37aece3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1536)\n",
       "    (wpe): Embedding(2048, 1536)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Linear4bit(in_features=1536, out_features=4608, bias=True)\n",
       "          (c_proj): Linear4bit(in_features=1536, out_features=1536, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Linear4bit(in_features=1536, out_features=6144, bias=True)\n",
       "          (c_proj): Linear4bit(in_features=6144, out_features=1536, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaef6a4-c5d6-4cc0-a132-84cfcaa31229",
   "metadata": {},
   "source": [
    "## Lora Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "801669d6-1a84-4896-aa08-75d61285d769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 25952256 || all params: 446513664 || trainables%: 5.812197496379416\n"
     ]
    }
   ],
   "source": [
    "config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"c_attn\", \"c_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf529c1a-40d3-4d06-b320-9b38984ea8d9",
   "metadata": {},
   "source": [
    "# Load Dataset (ru_instruct_gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31d6a6a5-3ada-4a28-ade8-27d46a175bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "  return f\"\"\"\n",
    "### Task: {data_point[\"instruction\"]}\n",
    "### Input: {data_point[\"input\"]}\n",
    "Output: {data_point[\"output\"]}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe596023-c57d-4fc1-8264-8c4ab9464ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for lksy/ru_instruct_gpt4 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/lksy/ru_instruct_gpt4\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"lksy/ru_instruct_gpt4\", split=\"train\")\n",
    "data = data.train_test_split(test_size=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d6d0005-6fee-4a97-bcc7-f96d295d62c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'full_output'],\n",
       "        num_rows: 14453\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'full_output'],\n",
       "        num_rows: 603\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2d879c-690f-416e-8132-04ae665089d2",
   "metadata": {},
   "source": [
    "## Few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41d239c1-1f08-4ed2-bb4f-ed3f1e9a0c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Task: Перескажи сюжет произведения \"Война и мир\" Льва Толстого.\n",
      "### Input: \n",
      "Output: \"Война и мир\" Льва Толстого - это культовый роман, который описывает российское общество в период с 1805 по 1812 год. Сюжетная линия следует за судьбами аристократических семей Ростовых, Болконских и Безуховых, их отношениями, любовными исканиями и встречами с историческими событиями. Главное событие романа - это Отечественная война 1812 года, сражение с французскими войсками Наполеона и его последующим поражением, что стало мощным импульсом для национального возрождения России.\n",
      "-----------------------------\n",
      "### Task: Опиши ситуацию из жизни, когда применение силы аргументов оказалось более действенным, чем аргумент силы.\n",
      "### Input: \n",
      "Output: Во время участия в студенческом проекте возник спор между двумя участниками группы о стратегии выполнения задачи. Один из участников, физически крупный парень, пытался настоять на своей точке зрения, используя аргумент силы, однако другой участник, хорошо подготовленный, находчивый и эрудированный, смог убедить большинство группы в правильности своего подхода, используя силу аргументов и предоставив научные данные и факты. В результате, группа выбрала более разумный и эффективный путь.\n",
      "-----------------------------\n",
      "### Task: Проанализируй и объясни результат применения указанного закона или принципа.\n",
      "### Input: закон Архимеда, корабль в бассейне\n",
      "Output: Применение закона Архимеда к кораблю в бассейне объясняет его плавание на воде: корабль выталкивает столько воды, сколько равно его собственному весу, и получает взаимную силу поддержки от воды, равную весу выталкиваемой воды, которая компенсирует силу тяжести корабля.\n",
      "-----------------------------\n",
      "### Task: Опиши основные причины возникновения Первой мировой войны и назови страны, участвовавшие в ней.\n",
      "### Input: \n",
      "Output: Основные причины возникновения Первой мировой войны - международные противоречия и споры за колонии и сферы влияния, национальные и этнические разногласия, дух национализма и агрессии, смерть австрийского принца Франца Фердинанда. В войне участвовали следующие страны: со стороны Антанты - Россия, Франция, Великобритания, Италия и США; со стороны Центральных держав - Германия, Австро-Венгрия и Османская империя.\n",
      "-----------------------------\n",
      "### Task: Создайте основу стихотворения на заданную тему из 4х строчек по 10 слогов.\n",
      "### Input: тема – осенний лес\n",
      "Output: Осень в лес пришла, играя красками,\n",
      "Золотом и кровью гроздья облаков,\n",
      "Тихо танцевали листья меж ветвями,\n",
      "Покрывая землю многоцветный снов.\n",
      "-----------------------------\n",
      "### Task: Выберите наиболее вероятную категорию товара по описанию продавца.\n",
      "### Input: Прекрасное устройство с большим экраном, отличной производительностью и мощным аккумулятором. Подойдет для игр, общения и работы.\n",
      "Output: Смартфон\n",
      "-----------------------------\n",
      "### Task: Исходя из описания ингредиента, определите, чем его можно заменить в рецепте.\n",
      "### Input: Рис - это вид злака, содержащий много углеводов, используется в кулинарии для приготовления множества блюд, служит основой для приготовления плова, суши и различных салатов.\n",
      "Output: киноа или гречка\n",
      "-----------------------------\n",
      "### Task: Опиши историческое событие, используя указанные имена, место и год.\n",
      "### Input: Наполеон, Александр I, Тильзит, 1807\n",
      "Output: В 1807 году в Тильзите произошла встреча между Наполеоном и Александром I, которая завершилась заключением мирного договора между Францией и Россией после серии поражений русских войск.\n",
      "-----------------------------\n",
      "### Task: Расскажи об истории появления и применения ядерной энергетики в мире.\n",
      "### Input: \n",
      "Output: История ядерной энергетики начинается с открытия ядерного деления в 1938 году немецкими учеными Отто Ханом и Фрицом Штрассманом. Это открытие стало основой для разработки атомной бомбы в ходе военных программ США (\"Манхэттенский проект\") и СССР. После Второй мировой войны страны начали искать мирное применение ядерной энергетики, и первая мирная атомная станция, ОБНИНСКАЯ АЭС, была запущена в СССР в 1954 году. С тех пор ядерная энергетика была внедрена в разных странах, и на сегодняшний день есть сотни атомных электростанций в мире. Однако существует опасение в связи с экологическими и безопасностью ядерных станций после таких аварий, как Чернобыль и Фукусима.\n",
      "-----------------------------\n",
      "### Task: Описать главную идею произведения литературы, сосредоточив внимание на конфликте и главных героях.\n",
      "### Input: \"Преступление и наказание\" Ф.М. Достоевского\n",
      "Output: \"Преступление и наказание\" Ф.М. Достоевского - это произведение о внутреннем конфликте главного героя Родиона Раскольникова, который решает совершить убийство, считая себя надчеловеческой личностью, обладающей правом на такое деяние. В романе основное внимание уделяется моральному кризису Раскольникова, борьбе между совестью и гордостью, а также его общению с остальными персонажами, на протяжении всей истории ведущими его к исповеди и исканию искупления.\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    tmp = data[\"train\"][i]\n",
    "    print(generate_prompt(tmp))\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0242a2e4-396a-42af-a474-eff56bdd0652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Преступление и наказание\" Ф.М. Достоевского - это произведение о внутреннем конфликте главного героя Родиона Раскольникова, который решает совершить убийство, считая себя надчеловеческой личностью, обладающей правом на такое деяние. В романе основное внимание уделяется моральному кризису Раскольникова, борьбе между совестью и гордостью, а также его общению с остальными персонажами, на протяжении всей истории ведущими его к исповеди и исканию искупления.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_prompt = generate_prompt(tmp)\n",
    "ex_prompt[ex_prompt.find(\"Output: \") + 8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0ff8906-a394-4bae-9f00-3cc3cd5b5af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'instruction': (self.data[idx]['instruction'] + '\\n' + self.data[idx]['input']).strip(),\n",
    "            'output': self.data[idx]['output'].strip()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af8d99c6-62c1-493f-86fb-3183d643b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    inputs, outputs = [], []\n",
    "    \n",
    "    for x in data:\n",
    "        inp = f'### Задание: {x[\"instruction\"]}\\n\\n### Ответ:'\n",
    "        input_ids = tokenizer(\n",
    "            inp,\n",
    "            add_special_tokens=True\n",
    "        )['input_ids']\n",
    "        label_ids = tokenizer(\n",
    "            x['output'] + tokenizer.eos_token,\n",
    "            add_special_tokens=False,\n",
    "            max_length=512,\n",
    "            truncation=True\n",
    "        )['input_ids']\n",
    "        inputs.append(torch.tensor(input_ids + label_ids))\n",
    "        outputs.append(torch.tensor([-100] * len(input_ids) + label_ids))\n",
    "        \n",
    "    input_ids = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(outputs, batch_first=True, padding_value=-100)\n",
    "        \n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'labels': labels,\n",
    "        'attention_mask': input_ids.ne(0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fff6c7b8-8bb2-43c8-a6f3-8ab7e7ca50d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(data['train'])\n",
    "eval_dataset = Dataset(data['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adef136e-4296-4ac8-bb42-83c1dbe34a32",
   "metadata": {},
   "source": [
    "# Metrics setup and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1f0f497-53ba-4e0d-80a6-0a6226ce0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import nltk\n",
    "\n",
    "metric = evaluate.load('rouge')\n",
    "def rouge_bleu_custom(pred):\n",
    "    references = pred.label_ids\n",
    "    predictions = pred.predictions[0]\n",
    "\n",
    "    ref_sent = []\n",
    "    pred_sent = []\n",
    "    macro_bleu = 0\n",
    "    for ref, predicted in zip(references, predictions):\n",
    "        # replace -100 with pad token\n",
    "        ref[ref == -100] = tokenizer.eos_token_id\n",
    "        ref_decoded = tokenizer.decode(ref, skip_special_tokens=True)\n",
    "        predicted[predicted == -100] = tokenizer.eos_token_id\n",
    "        predicted_decoded = tokenizer.decode(predicted, skip_special_tokens=True)\n",
    "        ref_sent.append(ref_decoded)\n",
    "        pred_sent.append(predicted_decoded)\n",
    "        \n",
    "        bleu_score = nltk.translate.bleu_score.sentence_bleu(\n",
    "                [ref_decoded],\n",
    "                predicted_decoded,\n",
    "                weights = [0.334, 0.333, 0.333]\n",
    "        )\n",
    "        macro_bleu += bleu_score\n",
    "    metrics_dict = metric.compute(predictions=pred_sent, references=ref_sent)\n",
    "    metrics_dict['bleu'] = macro_bleu / len(references)\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b9c3597-e4a7-4920-bc8d-336e97e72a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    \"\"\"\n",
    "    Original Trainer may have a memory leak. \n",
    "    This is a workaround to avoid storing too many tensors that are not needed.\n",
    "    \"\"\"\n",
    "\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    return pred_ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f765e816-db25-4ebf-8d89-9b1d6c58b4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3010' max='3010' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3010/3010 1:18:15, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.863300</td>\n",
       "      <td>2.015756</td>\n",
       "      <td>0.169717</td>\n",
       "      <td>0.092373</td>\n",
       "      <td>0.167370</td>\n",
       "      <td>0.167742</td>\n",
       "      <td>0.480105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.948600</td>\n",
       "      <td>1.965270</td>\n",
       "      <td>0.171252</td>\n",
       "      <td>0.088855</td>\n",
       "      <td>0.167642</td>\n",
       "      <td>0.168607</td>\n",
       "      <td>0.480183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.843000</td>\n",
       "      <td>1.952126</td>\n",
       "      <td>0.171044</td>\n",
       "      <td>0.088072</td>\n",
       "      <td>0.166528</td>\n",
       "      <td>0.168249</td>\n",
       "      <td>0.477032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.057000</td>\n",
       "      <td>1.938400</td>\n",
       "      <td>0.170484</td>\n",
       "      <td>0.087425</td>\n",
       "      <td>0.167087</td>\n",
       "      <td>0.167958</td>\n",
       "      <td>0.475642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "Checkpoint destination directory experiments/checkpoint-1806 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3010, training_loss=2.0073553546322542, metrics={'train_runtime': 4697.628, 'train_samples_per_second': 15.383, 'train_steps_per_second': 0.641, 'total_flos': 4.834354143041741e+16, 'train_loss': 2.0073553546322542, 'epoch': 5.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "      per_device_train_batch_size=6,\n",
    "      per_device_eval_batch_size=1,\n",
    "      gradient_accumulation_steps=4,\n",
    "      eval_accumulation_steps=4,\n",
    "      num_train_epochs=5,\n",
    "      learning_rate=2e-4,\n",
    "      fp16=True,\n",
    "      save_total_limit=3,\n",
    "      output_dir=\"experiments\",\n",
    "      optim=\"paged_adamw_8bit\",\n",
    "      lr_scheduler_type=\"cosine\",\n",
    "      warmup_ratio=0.05,\n",
    "      logging_dir = './logs',\n",
    "      report_to = 'tensorboard',\n",
    "      load_best_model_at_end = True,\n",
    "      evaluation_strategy ='epoch',\n",
    "      eval_steps=250,\n",
    "      logging_strategy='steps',\n",
    "      logging_steps=1,\n",
    "      save_strategy='epoch',\n",
    "      save_steps=2000,\n",
    "      seed=42,\n",
    "      remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=rouge_bleu_custom,\n",
    "    data_collator=collate_fn,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e2b34-14bc-41e4-b103-2a3b80e863a0",
   "metadata": {},
   "source": [
    "## Check Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "645ac387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alm/miniforge3/envs/assistant_nlp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import bitsandbytes as bnb\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "# using the style for the plot \n",
    "plt.style.use('dark_background') \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4c528ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    load_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c9a85de",
   "metadata": {},
   "outputs": [],
   "source": [
    "PEFT_MODEL = \"../models/gpt2\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(PEFT_MODEL)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    return_dict=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9abfce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model, PEFT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24f195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_len = []\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    output_len.append(len(train_data[\"output\"][i]))\n",
    "plt.hist(output_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2479481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alm/miniforge3/envs/assistant_nlp/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for lksy/ru_instruct_gpt4 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/lksy/ru_instruct_gpt4\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"lksy/ru_instruct_gpt4\", split=\"train\")\n",
    "data = data.train_test_split(test_size=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bffe4589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.712e+03, 4.725e+03, 3.754e+03, 1.072e+03, 1.570e+02, 2.500e+01,\n",
       "        6.000e+00, 1.000e+00, 0.000e+00, 1.000e+00]),\n",
       " array([1.0000e+00, 1.9370e+02, 3.8640e+02, 5.7910e+02, 7.7180e+02,\n",
       "        9.6450e+02, 1.1572e+03, 1.3499e+03, 1.5426e+03, 1.7353e+03,\n",
       "        1.9280e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_len = []\n",
    "\n",
    "for i in range(len(data['train'])):\n",
    "    output_len.append(len(data['train'][\"output\"][i]))\n",
    "plt.hist(output_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f5ab51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of Train Output Len: 297.0\n",
      "Mean of Train Output Len: 306.58\n"
     ]
    }
   ],
   "source": [
    "print(f\"Median of Train Output Len: {np.median(output_len)}\")\n",
    "print(f\"Mean of Train Output Len: {np.mean(output_len):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d20c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры для генерации\n",
    "generation_params = {\n",
    "    \"max_new_tokens\": 150,\n",
    "    \"num_beams\": 3,\n",
    "    \"early_stopping\": True,\n",
    "    \"no_repeat_ngram_size\": 2,\n",
    "    \"eos_token_id\": tokenizer.eos_token_id,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de9e0dc",
   "metadata": {},
   "source": [
    "## Рассмотрим обработку текстов из валидационного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4601d38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Задание: Составьте анекдот на основе предложенных слов.\n",
      "Бар, летучая мышь, бартендер\n",
      "\n",
      "### Ответ:Бармен: \"Уважаемые посетители, сегодня у нас необычный бар! Мы приготовили для вас сюрприз - летучую мышь!\"\n",
      "---------------------------------\n",
      "Validation Output: Однажды вечером в бар заходит летучая мышь, садится на табуретку и заказывает пиво. Бартендер удивлённо смотрит на неё и спрашивает: \"Ну и что ты, малышка, тут забыла?\" Летучая мышь отвечает: \"Ну, я пиво хотела выпить. Вино уже надоело, а крови капельки вообще не пробовала.\"\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Напиши рассказ о человеке, который вдруг обнаружил в себе удивительную способность.\n",
      "Денис | способность разговаривать с животными\n",
      "\n",
      "### Ответ:Однажды Денис случайно обнаружил, что может общаться с домашними животными. Однажды, гуляя по лесу, он встретил лису, которая рассказала ему о своих приключениях в лесу. Денис решил помочь лисе, и они вместе отправились на поиски пропавшего зайца. Когда они нашли его, заяц рассказал Денису о своей истории и о том, как ему удалось выжить в этом жестоком и опасном мире. В итоге, Денис и лиса нашли общий язык и стали друзьями, благодаря чему их дружба стала еще крепче.\n",
      "---------------------------------\n",
      "Validation Output: Денис однажды проснулся и обнаружил, что у него появилась удивительная способность разговаривать с животными. Используя этот дар, он помогал своему окружению, разрешая конфликты между людьми и разными видами животных, а также спасая их от опасности и несчастий.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Составьте короткую историю про мальчика по имени Василий и его нового друга Михаила.\n",
      "\n",
      "### Ответ:Василий и Михаил были неразлучными друзьями с самого детства. Они всегда проводили время вместе, играли в разные игры, катались на велосипедах и ходили в походы. Однажды, когда они отправились в поход, их пути пересеклись, и они стали лучшими друзьями на всю жизнь.\n",
      "---------------------------------\n",
      "Validation Output: Мальчик по имени Василий однажды отправился в парк, чтобы погулять. Там он встретил мальчика по имени Михаил, который искал свою потерянную собаку. Василий решил помочь Михаилу в поисках, и вместе они отыскали собаку. С того дня Василий и Михаил стали неразлучными друзьями.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Предложите принципы здоровой работы с компьютером, чтобы избежать заболеваний, связанных с продолжительной работой с ПК.\n",
      "\n",
      "### Ответ:1. Регулярная очистка от пыли и замена термопасты на процессоре и видеокарте. 2. Использование антистатических ковриков для клавиатуры и мыши. 3. Уменьшение времени работы за компьютером. 4. Избегание чрезмерной нагрузки на глаза и позвоночник. 5. Правильное распределение времени между работой и отдыхом.\n",
      "---------------------------------\n",
      "Validation Output: 1. Регулируйте высоту стола и стула так, чтобы сохранять прямую осанку.\n",
      "2. Следите за расстоянием между глазами и экраном компьютера (45-70 см).\n",
      "3. Отрегулируйте освещение и контраст экрана, чтобы избежать напряжения глаз.\n",
      "4. Делайте перерывы каждые 45-60 минут работы, чтобы отдохнуть и размять мышцы.\n",
      "5. Следите за своей осанкой и положением рук при печати на клавиатуре.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Преобразуйте предложение, заменив прилагательные на их синонимы.\n",
      "В красивом лесу растут огромные деревья.\n",
      "\n",
      "### Ответ:В живописном лесу растет множество деревьев.\n",
      "---------------------------------\n",
      "Validation Output: В живописном лесу растут гигантские деревья.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Сформулируй совет для человека, который хочет улучшить свои коммуникативные навыки.\n",
      "\n",
      "### Ответ:Для улучшения своих коммуникативных навыков, обратите внимание на следующие советы: \n",
      "1. Регулярно практикуйтесь в устной и письменной коммуникации, используя различные техники и приемы, такие как вопросы, ответы, вопросы-ответы и т.д. Это поможет вам лучше понимать собеседника и находить общий язык с ним;\n",
      "2. Развивайте навыки общения в социальных сетях и мессенджерах, где вы можете делиться своими мыслями и опытом с другими пользователями, а также общаться с коллегами и друзьями;  \n",
      "\n",
      "3. Изучайте иностранные языки, чтобы расширить свой словарный запас и расширить кругозор. Кроме того, учитесь общаться на английском языке, так как он является одним из самых распространенных языков в мире.\n",
      "---------------------------------\n",
      "Validation Output: Чтобы улучшить свои коммуникативные навыки, активно слушайте собеседника, задавайте открытые вопросы, контролируйте свою невербальную коммуникацию и регулярно тренируйте общение с разными людьми, тем самым развивая эмпатию и адаптируясь к различным стилям общения.\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Найди первые пять чисел Фибоначчи.\n",
      "\n",
      "### Ответ:1, 2, 3, 4, 5\n",
      "---------------------------------\n",
      "Validation Output: 0, 1, 1, 2, 3\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Сформулируй аналитический вопрос о возможных тенденциях в мировой политике на основе приведенных данных.\n",
      "экономический кризис, распространение вооруженных конфликтов, усиление экологических проблем.\n",
      "\n",
      "### Ответ:Существует ли вероятность экономического кризиса в мире в ближайшие годы, и если да, то каковы его масштабы и причины?\n",
      "---------------------------------\n",
      "Validation Output: Как экономический кризис, распространение вооруженных конфликтов и усиление экологических проблем могут влиять на тенденции и перспективы в мировой политике в ближайшем будущем?\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Определите, к какому литературному жанру относится произведение на основе приведенного описания.\n",
      "Фантастический роман, в котором люди обладают сверхъестественными способностями и борются с злом.\n",
      "\n",
      "### Ответ:Фэнтези\n",
      "---------------------------------\n",
      "Validation Output: Фэнтези\n",
      "\n",
      "\n",
      "\n",
      "### Задание: Расскажите о важности сбалансированного питания для здоровья и приведите примеры полезных продуктов.\n",
      "\n",
      "### Ответ:Сбалансированное питание играет ключевую роль в поддержании здоровья, так как оно обеспечивает организм всеми необходимыми питательными веществами, витаминами, минералами и микроэлементами, необходимыми для нормального функционирования всех систем и органов. Примеры сбалансированных продуктов включают фрукты, овощи, злаковые, бобовые, орехи, рыбу и морепродукты.\n",
      "---------------------------------\n",
      "Validation Output: Сбалансированное питание играет важную роль для поддержания здоровья, так как помогает предотвратить многие заболевания и способствует нормальному функционированию организма. Полезные продукты включают: овощи и фрукты, обеспечивающие необходимые витамины и минералы; зерновые, содержащие клетчатку и медленные углеводы; магерые источники протеина, такие как курятина, рыба и морепродукты; нежирные молочные продукты, обеспечивающие кальций и витамин D; орехи и семена, богатые здоровыми жирами.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_data = data['test']\n",
    "\n",
    "for _ in range(10):\n",
    "  i = np.random.randint(len(val_data))\n",
    "  task = (val_data[i]['instruction'] + '\\n' + val_data[i]['input']).strip()\n",
    "  prompt = f'### Задание: {task}\\n\\n### Ответ:'\n",
    "  original_prompt = f'### Задание: {task}\\n\\n### Ответ:'\n",
    "  original_prompt += val_data[i]['output']\n",
    "\n",
    "  device = \"cuda:0\"\n",
    "  encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "  with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids = encoding.input_ids,\n",
    "        attention_mask = encoding.attention_mask,\n",
    "        **generation_params,\n",
    "  )\n",
    "  pred_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "  # sequence_start = pred_text.find(\"Output: \") + 8\n",
    "  print(pred_text)\n",
    "  print(\"---------------------------------\")\n",
    "  print(\"Validation Output: \" + val_data[\"output\"][i])\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59247a86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
